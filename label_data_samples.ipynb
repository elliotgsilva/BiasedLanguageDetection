{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "#nltk.download('wordnet')\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates new sample of data to be labeled\n",
    "def please_label(master_file, new_file, sample_num=100):\n",
    "  master_df = pd.read_excel(master_file,index_col=0)\n",
    "  to_label_df = master_df[master_df.true_pos==-1]\n",
    "  output_df = to_label_df.sample(sample_num)\n",
    "  output_df.to_excel(new_file)\n",
    "  return output_df\n",
    "\n",
    "#Create fixed chunks of shuffled data for people to label\n",
    "def batch_please_label(master_file, batch_folder, sample_num=100):\n",
    "  master_df = pd.read_excel(master_file,index_col=0).drop(labels=[\"lemmatized\",\"problematic\"],axis=1)\n",
    "  to_label_df = master_df[master_df.true_pos==-1].sample(frac=1,random_state=0)\n",
    "  row_num = to_label_df.shape[0]\n",
    "  batches = row_num//sample_num\n",
    "  print(batches)\n",
    "  #assert 1==0\n",
    "  \n",
    "  for start_bin in range(batches):\n",
    "    end_bin = start_bin+1\n",
    "    temp = to_label_df.iloc[start_bin*sample_num:end_bin*sample_num,:]\n",
    "    if end_bin == batches and row_num%sample_num>0:#we have leftover rows to deal with\n",
    "      extra = to_label_df.iloc[end_bin*sample_num:,:]\n",
    "      extra.to_excel(batch_folder+\"batch_\"+str(end_bin)+\".xlsx\")\n",
    "    temp.to_excel(batch_folder+\"batch_\"+str(start_bin)+\".xlsx\")\n",
    "  print(f\"Full Batches: {batches}\")\n",
    "  print(f\"Partial Batch?: {row_num%sample_num>0}\")\n",
    "  print(f\"Go check {batch_folder}\")\n",
    "    \n",
    "  \n",
    "#Update our running master_df_labeled with multiple new files\n",
    "def batch_merge_into_master(master_file, batch_folder):\n",
    "  batch_files = os.listdir(batch_folder)\n",
    "  print(batch_files)\n",
    "  master_df_labeled = pd.read_excel(master_file,index_col=0)\n",
    "  #master_df_labeled = pickle.load(open(master_file, \"rb\"))\n",
    "  for new_file in batch_files:\n",
    "    print(new_file)\n",
    "    if re.match('batch_[0-9]*\\.xlsx',new_file):\n",
    "      new_df = pd.read_excel(batch_folder+new_file,index_col=0)\n",
    "      master_df_labeled.update(new_df.true_pos)\n",
    "      #master_df_labeled = merge_into_master(master_file, batch_folder+new_file, batch=True)\n",
    "      print_tf_pos(master_df_labeled)\n",
    "  master_df_labeled.to_excel(master_file)\n",
    "  #pickle.dump(master_df_labeled,open(master_file,\"wb\"))\n",
    "  return master_df_labeled\n",
    "\n",
    "#Update our running master_df_labeled, main function to produce files for dataloaders\n",
    "def merge_into_master(master_file, new_file, grounds_file, batch=False):\n",
    "  master_df_labeled = pd.read_excel(master_file,index_col=0)\n",
    "  new_df = pd.read_excel(new_file,index_col=0)\n",
    "\n",
    "  master_df_labeled.update(new_df.true_pos)\n",
    "  master_df_labeled.to_excel(master_file)\n",
    "#   if not batch:\n",
    "#     ground_truths_df = produce_ground_truths(master_df_labeled, grounds_file)\n",
    "#     master_df_labeled.to_excel(master_file)\n",
    "#     pickle.dump(master_df_labeled,open(\"./data/master_df_labeled.p\",\"wb\"))\n",
    "#     return master_df_labeled, ground_truths_df\n",
    "  \n",
    "  pickle.dump(master_df_labeled,open(\"./data/master_df_labeled.p\",\"wb\"))\n",
    "  return master_df_labeled\n",
    "  \n",
    "\n",
    "#Produces ground_truths_df\n",
    "def produce_ground_truths(master_df_labeled, grounds_file):\n",
    "  ground_truths_df = master_df_labeled[master_df_labeled.true_pos!=-1]\n",
    "  ground_truths_df.to_excel(grounds_file)\n",
    "  pickle.dump(ground_truths_df,open(\"./data/ground_truths_df.p\",\"wb\"))\n",
    "  return ground_truths_df\n",
    "\n",
    "#Print out how many examples are labeled as True or False Positives\n",
    "def print_tf_pos(master_df_labeled):\n",
    "  print(f\"Count of true positives: {master_df_labeled[master_df_labeled.true_pos==1].shape[0]}\")\n",
    "  print(f\"Count of false positives: {master_df_labeled[master_df_labeled.true_pos==0].shape[0]}\")\n",
    "  assert master_df_labeled[master_df_labeled.problematic==0].shape[0]==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All excel file paths here, pickle paths are used by other scripts so hardcoded\n",
    "master_file = \"./data/master_df_labeled.xlsx\"\n",
    "#new sampled data to be labeled\n",
    "new_file = \"./data/please_label.xlsx\"\n",
    "grounds_file = \"./data/ground_truths.xlsx\"\n",
    "batch_folder = \"./data/please_label_batch/100/\"\n",
    "#batch_labeled = \"./data/please_label_batch/labeled/\"\n",
    "batch_labeled = \"/Users/echo/Google Drive File Stream/My Drive/2019 Fall/Capstone group/FairFrame Annotations/labeled/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Workflow\n",
    "1. Print current true and false positive counts\n",
    "2. After labeling, update our running master file (merge_into_master)\n",
    "3. Print new true and false positive counts to check, also select specific example to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of true positives: 471\n",
      "Count of false positives: 631\n",
      "(111029, 6)\n"
     ]
    }
   ],
   "source": [
    "#Print current true and false positive counts\n",
    "#master_df_labeled.to_excel(\"./data/master_df_labeled.xlsx\")\n",
    "master_df_labeled = pd.read_excel(master_file,index_col=0)\n",
    "\n",
    "print_tf_pos(master_df_labeled)\n",
    "print(master_df_labeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_2.xlsx', 'batch_3.xlsx', 'batch_7.xlsx', 'batch_1.xlsx', 'batch_0.xlsx', 'batch_9.xlsx', 'batch_10.xlsx', 'batch_11.xlsx', 'batch_5.xlsx', 'batch_6.xlsx', 'batch_12.xlsx', 'Icon\\r']\n",
      "batch_2.xlsx\n",
      "Count of true positives: 85\n",
      "Count of false positives: 99\n",
      "batch_3.xlsx\n",
      "Count of true positives: 124\n",
      "Count of false positives: 147\n",
      "batch_7.xlsx\n",
      "Count of true positives: 156\n",
      "Count of false positives: 210\n",
      "batch_1.xlsx\n",
      "Count of true positives: 196\n",
      "Count of false positives: 261\n",
      "batch_0.xlsx\n",
      "Count of true positives: 237\n",
      "Count of false positives: 308\n",
      "batch_9.xlsx\n",
      "Count of true positives: 284\n",
      "Count of false positives: 358\n",
      "batch_10.xlsx\n",
      "Count of true positives: 321\n",
      "Count of false positives: 411\n",
      "batch_11.xlsx\n",
      "Count of true positives: 349\n",
      "Count of false positives: 472\n",
      "batch_5.xlsx\n",
      "Count of true positives: 384\n",
      "Count of false positives: 531\n",
      "batch_6.xlsx\n",
      "Count of true positives: 434\n",
      "Count of false positives: 577\n",
      "batch_12.xlsx\n",
      "Count of true positives: 471\n",
      "Count of false positives: 631\n",
      "Icon\n",
      "Count of true positives: 471\n",
      "Count of false positives: 631\n",
      "(111029, 6)\n"
     ]
    }
   ],
   "source": [
    "master_df_labeled = batch_merge_into_master(\"./data/master_df_labeled.xlsx\", batch_labeled)\n",
    "print_tf_pos(master_df_labeled)\n",
    "print(master_df_labeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_labeled.to_excel(\"./data/master_df_labeled.xlsx\")\n",
    "pickle.dump(master_df_labeled,open(master_file,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109\n",
      "Full Batches: 1109\n",
      "Partial Batch?: True\n",
      "Go check ./data/please_label_batch/100/\n"
     ]
    }
   ],
   "source": [
    "#Generate fixed batch to label\n",
    "#batch_please_label(master_file, batch_folder, sample_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Labeling Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524\n",
      "448\n"
     ]
    }
   ],
   "source": [
    "master_df = pickle.load(open(\"./data/master_df.p\", \"rb\"))\n",
    "master_df[\"lemmatized\"] = [wordnet_lemmatizer.lemmatize(w) for w in master_df.flagged_word]\n",
    "#\n",
    "print(len(set(master_df.flagged_word)))\n",
    "print(len(set(master_df.lemmatized)))\n",
    "#print(set(master_df.flagged_word)-set(master_df.lemmatized))\n",
    "# print(sorted(list(set(master_df.lemmatized)),key=str.lower))\n",
    "# master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating random sample from master_df to label\n",
    "# sampled = master_df[master_df.problematic==1].sample(500)\n",
    "# sampled.to_excel(\"./data/fptp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of true positives: 52\n",
      "Count of false positives: 44\n"
     ]
    }
   ],
   "source": [
    "#merge by row index\n",
    "labeled = pd.read_excel(\"./data/fptp_labeled.xlsx\",index_col=0)\n",
    "master_df_labeled = master_df.join(labeled.true_pos).fillna(-1)\n",
    "master_df_labeled = master_df_labeled[master_df_labeled.problematic==1]\n",
    "#master_df_labeled\n",
    "print_tf_pos(master_df_labeled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#master file to continuously update\n",
    "master_df_labeled.to_excel(\"./data/master_df_labeled.xlsx\")\n",
    "pickle.dump(master_df_labeled,open(\"./data/master_df_labeled.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
