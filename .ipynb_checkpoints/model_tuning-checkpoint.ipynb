{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zno22FtJPX9z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import get_mnist_dataset, get_data_loader\n",
    "#from utils import *\n",
    "#from models import *\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "from generate_dataloaders import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaJEVd0wPX94"
   },
   "source": [
    "## Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vi6hPzadPX95"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_filename,val_filename):\n",
    "    path = os.getcwd()\n",
    "    data_dir = path + '/data/'\n",
    "    train_dataloader = pkl.load(open(data_dir + train_filename,'rb'))\n",
    "    val_dataloader = pkl.load(open(data_dir + val_filename,'rb'))\n",
    "    return train_dataloader,val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLzh007PX98"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = path + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq-jDGFIPX99"
   },
   "outputs": [],
   "source": [
    "train_loader,val_loader = get_dataloaders('train_dataloader.p','val_dataloader.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tQEhYjtPX-A"
   },
   "outputs": [],
   "source": [
    "ground_truth_dataloader = pkl.load(open(data_dir + 'ground_truth_dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzz8lwNQPX-B",
    "outputId": "690cb77f-2525-4c5a-ea14-a162716e34d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69-v6pTCPX-E"
   },
   "source": [
    "## Scratchwork (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbzHfEqEPX-F",
    "outputId": "e190e666-75a9-43f4-881c-307d2e18993a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(train_loader):\n",
    "    print(len(x[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6foV2y9kPX-H",
    "outputId": "1201dae2-e377-4311-c1af-3527d5b632c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5])\n",
      "tensor([[[1., 2., 3., 4., 5.],\n",
      "         [3., 3., 3., 3., 3.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [2., 1., 2., 1., 2.]],\n",
      "\n",
      "        [[0., 1., 0., 1., 0.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [2., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 2.]]])\n",
      "torch.Size([2])\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "minibatch = torch.tensor([\n",
    "                            [[1,2,3,4,5],[3,3,3,3,3],[1,1,1,1,1],[2,1,2,1,2]],\n",
    "                            [[0,1,0,1,0],[1,1,1,1,1],[2,0,0,0,0],[0,0,0,0,2]]\n",
    "                         ], dtype=torch.float32)\n",
    "\n",
    "flagged_indices = torch.tensor([1,2])\n",
    "\n",
    "upweight_value = 10\n",
    "\n",
    "print(minibatch.shape)\n",
    "print(minibatch)\n",
    "\n",
    "print(flagged_indices.shape)\n",
    "print(flagged_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrRatzhRPX-J",
    "outputId": "283ee2e9-6cd0-439b-a2db-2996aeda85fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "2 4 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [30., 30., 30., 30., 30.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 2.,  1.,  2.,  1.,  2.]],\n",
       "\n",
       "        [[ 0.,  1.,  0.,  1.,  0.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.],\n",
       "         [20.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  2.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_tokens, emb_dim = minibatch.shape\n",
    "print(type(minibatch))\n",
    "minibatch[range(batch_size),flagged_indices,:] *= upweight_value\n",
    "print(batch_size, num_tokens, emb_dim)\n",
    "minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3-0cZqzPX-K",
    "outputId": "9b9e9298-fc39-4fa3-cb20-94fc22dee9bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6154, 2.6154, 2.7692, 2.7692, 2.9231],\n",
       "        [1.6154, 0.1538, 0.0769, 0.1538, 0.2308]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch.sum(1) / (num_tokens + upweight_value - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFiD86rvPX-M",
    "outputId": "1f4c46ab-5c61-40fc-d9cb-30256b33acdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xyk-TsdPX-O"
   },
   "outputs": [],
   "source": [
    "embed = torch.tensor(np.array([[2,4,5,6],[1,3,45,7],[3,4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paQ0ohcwPX-Q"
   },
   "outputs": [],
   "source": [
    "centers = torch.tensor(np.array(([2,3,4,5],[1,2,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBKi1uXdPX-R",
    "outputId": "a5c9c793-4abb-4375-e0fb-13f56bef5718"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   3,    7],\n",
       "        [1686, 1686],\n",
       "        [   4,   10]])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((embed[:,None,:]-centers)**2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZ2VcvBzPX-T",
    "outputId": "f2369f2c-a0f3-4b62-aa0d-ffc4e9ef7c22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distances, cluster_assignments = torch.sum((embed[:,None,:]-centers)**2, 2).min(1)\n",
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OU5oKfrGPX-V",
    "outputId": "ace2c69a-d28e-444a-bc38-b1feead074dc"
   },
   "outputs": [],
   "source": [
    "for i, (tokens, labels, flagged_indices) in enumerate(train_loader):\n",
    "    #print(tokens, labels, flagged_indices)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_assts = torch.LongTensor([1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
    "        0, 0, 0, 1, 0, 0, 0, 1])\n",
    "k = 2\n",
    "bin_counts = torch.bincount(cluster_assts,minlength=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16., 16.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_counts = bin_counts.type(torch.FloatTensor).to(current_device)\n",
    "bin_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt6N9QCPX-X"
   },
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puweJhdxPX-Y"
   },
   "source": [
    "NOTE: Data loader is defined as:\n",
    "- tuple: (tokens, flagged_index, problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8BZ-QhNPX-Z"
   },
   "outputs": [],
   "source": [
    "class neuralNetBow(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n",
    "    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n",
    "    def __init__(self, vocab_size, emb_dim, upweight=10):\n",
    "        super(neuralNetBow, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=2)\n",
    "        self.upweight = upweight\n",
    "    \n",
    "    def forward(self, tokens, flagged_index):\n",
    "        batch_size, num_tokens = tokens.shape\n",
    "        embedding = self.embed(tokens)\n",
    "#         print(embedding.shape) # below assumes \"batch_size x num_tokens x Emb_dim\" (VERIFY)\n",
    "        \n",
    "        # upweight by flagged_index\n",
    "#         print(type(embedding))\n",
    "        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n",
    "        \n",
    "        # average across embeddings\n",
    "        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n",
    "        \n",
    "        return embedding_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGsqcnEtPX-a"
   },
   "source": [
    "### Clustering Stuff (un-tailored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrgIYm8JPX-b"
   },
   "outputs": [],
   "source": [
    "class KMeansCriterion(nn.Module):\n",
    "    \n",
    "    def __init__(self, lmbda):\n",
    "        super().__init__()\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def forward(self, embeddings, centroids):\n",
    "        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n",
    "        cluster_distances, cluster_assignments = distances.min(1)\n",
    "        loss = self.lmbda * cluster_distances.sum()\n",
    "        return loss, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJohK2aPX-d"
   },
   "outputs": [],
   "source": [
    "def centroid_init(k, d, dataloader, model, current_device):\n",
    "    ## Here we ideally don't want to do randomized/zero initialization\n",
    "    centroid_sums = torch.zeros(k, d).to(current_device)\n",
    "    centroid_counts = torch.zeros(k).to(current_device)\n",
    "    for (tokens, labels, flagged_indices) in dataloader:\n",
    "        # cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n",
    "        cluster_assignments = labels.to(current_device)\n",
    "        \n",
    "        model.eval()\n",
    "        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n",
    "    \n",
    "        update_clusters(centroid_sums, centroid_counts,\n",
    "                        cluster_assignments, sentence_embed.to(current_device))\n",
    "    \n",
    "    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n",
    "    return centroid_means.clone()\n",
    "\n",
    "def update_clusters(centroid_sums, centroid_counts,\n",
    "                    cluster_assignments, embeddings):\n",
    "    k = centroid_sums.size(0)\n",
    "\n",
    "    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n",
    "    bin_counts = torch.bincount(cluster_assignments,minlength=k).type(torch.FloatTensor).to(current_device)\n",
    "    centroid_counts.add_(bin_counts)\n",
    "    \n",
    "    #np_cluster_assignments = cluster_assignments.to('cpu')\n",
    "    #np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n",
    "    #centroid_counts.add_(torch.FloatTensor(np_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3wynM7fPX-h"
   },
   "source": [
    "### Training Function (un-tailored, needs alterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KglsYxPJPX-i"
   },
   "outputs": [],
   "source": [
    "def train_model(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs=10, path_to_save=None, print_every = 100):\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus > 0:\n",
    "        current_device = 'cuda'\n",
    "    else:\n",
    "        current_device = 'cpu'\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('{} | Epoch {}'.format(dt.datetime.now(), epoch))\n",
    "        model.train()\n",
    "        k, d = centroids.size()\n",
    "        centroid_sums = torch.zeros_like(centroids).to(current_device)\n",
    "        centroid_counts = torch.zeros(k).to(current_device)\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "        # run one epoch of gradient descent on autoencoders wrt centroids\n",
    "        for i, (tokens, labels, flagged_indices) in tqdm(enumerate(train_loader)):\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "\n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids.detach())\n",
    "\n",
    "            # run update step\n",
    "            optimizer.zero_grad()\n",
    "            cluster_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Add loss to the epoch loss\n",
    "            total_epoch_loss += cluster_loss.data\n",
    "\n",
    "            # store centroid sums and counts in memory for later centering\n",
    "            update_clusters(centroid_sums, centroid_counts,\n",
    "                            cluster_assignments, sentence_embed)\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                losses = cluster_loss.data/len(tokens)\n",
    "                print('Average training loss at batch ',i,': %.3f' % losses)\n",
    "            \n",
    "        total_epoch_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(total_epoch_loss)\n",
    "        print('Average training loss after epoch ',epoch,': %.3f' % total_epoch_loss)\n",
    "        \n",
    "        # update centroids based on assignments from autoencoders\n",
    "        centroids = centroid_sums / (centroid_counts[:, None] + 1).to(current_device)\n",
    "        \n",
    "        # calculate validation loss after every epoch\n",
    "        total_validation_loss = 0\n",
    "        for i, (tokens, labels, flagged_indices) in enumerate(valid_loader):\n",
    "            model.eval()\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "            \n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n",
    "            \n",
    "            #Add loss to the validation loss\n",
    "            total_validation_loss += cluster_loss.data\n",
    "\n",
    "        total_validation_loss /= len(valid_loader.dataset)\n",
    "        val_losses.append(total_validation_loss)\n",
    "        print('Average validation loss after epoch ',epoch,': %.3f' % total_validation_loss)\n",
    "        \n",
    "        if path_to_save == None:\n",
    "            pass\n",
    "        else:\n",
    "            torch.save(model.state_dict(), path_to_save+'_dict_epoch'+str(epoch)+'.pt')\n",
    "            torch.save(centroids, path_to_save+'_centroids_epoch'+str(epoch))\n",
    "            torch.save(train_losses, path_to_save+'_train_losses')\n",
    "            torch.save(val_losses, path_to_save+'_val_losses')\n",
    "        \n",
    "    return model, centroids, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0kEtvbqPX-k"
   },
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'vocab_size': 20000,\n",
    "    'emb_dim': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pBet75ZPX-m"
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "\n",
    "model = neuralNetBow(opts['vocab_size'], opts['emb_dim']).to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTFO2vp-PX-o"
   },
   "outputs": [],
   "source": [
    "# model = neuralNetBow(opts['vocab_size'], opts['emb_dim'])\n",
    "centroids = centroid_init(2, opts['emb_dim'],ground_truth_dataloader, model, current_device)\n",
    "criterion = KMeansCriterion(1).to(current_device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xya2NiqcPX-q",
    "outputId": "59b3072e-c567-4e18-a242-ba8298f08e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.3282e-01, -4.9162e-01, -2.4064e-01,  ...,  2.6259e-01,\n",
       "          1.1852e-01,  3.5728e-02],\n",
       "        [ 2.2224e-01, -4.7257e-01, -1.2804e-01,  ...,  1.1401e-01,\n",
       "          6.7910e-02, -2.6494e-04]], grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1573355494600,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 300
    },
    "id": "2It2SvzjPX-s",
    "outputId": "5de6949c-7e9e-4ade-f222-5eb28f5347db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8813,
     "status": "error",
     "timestamp": 1573355511003,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 300
    },
    "id": "rgwMd27mPX-u",
    "outputId": "063ebc41-be3c-4474-d92c-7bd0680bb366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "1it [00:00,  7.21it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-13 18:12:16.519000 | Epoch 0\n",
      "Average training loss at batch  0 : 50.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "3it [00:00,  8.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "5it [00:00,  8.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "7it [00:00,  9.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "9it [00:00, 10.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "11it [00:00, 10.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "13it [00:01, 10.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "15it [00:01, 11.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "17it [00:01, 11.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "19it [00:01, 11.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "21it [00:01, 11.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "23it [00:02, 11.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "25it [00:02, 11.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "27it [00:02, 11.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "29it [00:02, 11.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "31it [00:02, 11.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "33it [00:02, 11.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "35it [00:03, 11.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "37it [00:03, 11.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "39it [00:03, 11.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "41it [00:03, 11.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "43it [00:03, 11.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "45it [00:03, 10.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "47it [00:04, 10.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "49it [00:04, 10.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "51it [00:04, 11.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "53it [00:04, 11.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "55it [00:04, 11.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "57it [00:05, 11.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "59it [00:05, 11.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "61it [00:05, 11.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "63it [00:05, 11.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "65it [00:05, 11.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "67it [00:05, 11.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "69it [00:06, 11.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "71it [00:06, 10.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "73it [00:06, 11.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "75it [00:06, 11.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "77it [00:06, 11.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "79it [00:06, 11.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "81it [00:07, 11.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "83it [00:07, 11.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "85it [00:07, 11.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "87it [00:07, 11.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "89it [00:07, 11.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "91it [00:08, 11.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "93it [00:08, 10.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "95it [00:08, 11.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "97it [00:08, 11.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "99it [00:08, 11.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "101it [00:08, 11.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "103it [00:09, 11.34it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  100 : 17.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "105it [00:09, 11.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "107it [00:09, 11.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "109it [00:09, 11.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "111it [00:09, 11.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "113it [00:10, 11.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "115it [00:10, 11.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "117it [00:10, 11.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "119it [00:10, 10.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "121it [00:10, 11.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "123it [00:10, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "125it [00:11, 11.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "127it [00:11, 11.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "129it [00:11, 11.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "131it [00:11, 11.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "133it [00:11, 11.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "135it [00:11, 11.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "137it [00:12, 11.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "139it [00:12, 11.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "141it [00:12, 10.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "143it [00:12, 10.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "145it [00:12, 10.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "147it [00:13, 10.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "149it [00:13, 10.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "151it [00:13, 10.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "153it [00:13, 10.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "155it [00:13, 10.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "157it [00:14, 11.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "159it [00:14, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "161it [00:14, 11.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "163it [00:14, 11.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "165it [00:14, 11.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "167it [00:14, 11.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "169it [00:15, 11.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "171it [00:15, 11.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "173it [00:15, 11.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "175it [00:15, 11.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "177it [00:15, 11.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "179it [00:15, 11.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "181it [00:16, 11.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "183it [00:16, 11.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "185it [00:16, 11.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "187it [00:16, 11.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "189it [00:16, 11.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "191it [00:16, 11.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "193it [00:17, 11.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "195it [00:17, 11.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "197it [00:17, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "199it [00:17, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "201it [00:17, 11.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "203it [00:17, 11.95it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  200 : 9.037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "205it [00:18, 11.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "207it [00:18, 11.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "209it [00:18, 11.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "211it [00:18, 12.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "213it [00:18, 11.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "215it [00:18, 12.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "217it [00:19, 12.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "219it [00:19, 12.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "221it [00:19, 12.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "223it [00:19, 12.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "225it [00:19, 11.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "227it [00:19, 11.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "229it [00:20, 12.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "231it [00:20, 12.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "233it [00:20, 12.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "235it [00:20, 12.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "237it [00:20, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "239it [00:20, 10.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "241it [00:21, 10.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "243it [00:21, 10.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "245it [00:21, 10.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "247it [00:21, 10.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "249it [00:21,  9.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "251it [00:22, 10.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "253it [00:22, 10.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "255it [00:22, 10.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "257it [00:22, 10.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "259it [00:22, 10.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "261it [00:23, 10.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "263it [00:23, 10.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "265it [00:23, 10.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "267it [00:23, 10.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "269it [00:23, 10.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "271it [00:24, 10.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "273it [00:24, 10.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "275it [00:24, 10.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "277it [00:24, 10.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "279it [00:24, 10.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "281it [00:24, 10.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "283it [00:25, 10.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "285it [00:25, 10.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "287it [00:25, 10.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "289it [00:25, 10.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "291it [00:25, 10.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "293it [00:26, 10.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "295it [00:26, 10.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "297it [00:26, 10.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "299it [00:26, 10.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "301it [00:26, 10.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "303it [00:27, 10.69it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  300 : 6.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "305it [00:27, 10.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "307it [00:27, 10.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "309it [00:27, 10.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "311it [00:27, 10.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "313it [00:28, 10.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "315it [00:28, 10.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "317it [00:28, 10.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "319it [00:28, 11.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "321it [00:28, 10.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "323it [00:28, 11.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "325it [00:29, 11.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "327it [00:29, 11.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "329it [00:29, 11.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "331it [00:29, 11.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "333it [00:29, 11.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "335it [00:29, 11.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "337it [00:30, 11.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "339it [00:30, 11.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "341it [00:30, 11.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "343it [00:30, 11.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "345it [00:30, 11.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "347it [00:30, 11.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "349it [00:31, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "351it [00:31, 11.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "353it [00:31, 11.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "355it [00:31, 11.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "357it [00:31, 11.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "359it [00:32, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "361it [00:32, 11.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "363it [00:32, 11.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "365it [00:32, 11.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "367it [00:32, 11.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "369it [00:32, 11.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "371it [00:33, 11.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "373it [00:33, 11.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "375it [00:33, 11.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "377it [00:33, 11.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "379it [00:33, 11.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "381it [00:33, 11.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "383it [00:34, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "385it [00:34, 11.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "387it [00:34, 11.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "389it [00:34, 11.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "391it [00:34, 11.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "393it [00:34, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "395it [00:35, 11.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "397it [00:35, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "399it [00:35, 11.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "401it [00:35, 11.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "403it [00:35, 11.72it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  400 : 3.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "405it [00:36, 11.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "407it [00:36, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "409it [00:36, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "411it [00:36, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "413it [00:36, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "415it [00:36, 11.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "417it [00:37, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "419it [00:37, 11.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "421it [00:37, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "423it [00:37, 11.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "425it [00:37, 11.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "427it [00:37, 11.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "429it [00:38, 11.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "431it [00:38, 11.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "433it [00:38, 11.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "435it [00:38, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "437it [00:38, 11.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "439it [00:38, 11.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "441it [00:39, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "443it [00:39, 11.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "445it [00:39, 11.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "447it [00:39, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "449it [00:39, 11.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "451it [00:39, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "453it [00:40, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "455it [00:40, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "457it [00:40, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "459it [00:40, 11.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "461it [00:40, 11.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "463it [00:40, 11.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "465it [00:41, 11.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "467it [00:41, 11.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "469it [00:41, 12.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "471it [00:41, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "473it [00:41, 11.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "475it [00:41, 11.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "477it [00:42, 11.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "479it [00:42, 11.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "481it [00:42, 11.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "483it [00:42, 11.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "485it [00:42, 11.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "487it [00:43, 11.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "489it [00:43, 11.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "491it [00:43, 11.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "493it [00:43, 11.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "495it [00:43, 11.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "497it [00:43, 11.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "499it [00:44, 11.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "501it [00:44, 11.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "503it [00:44, 11.67it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  500 : 3.033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "505it [00:44, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "507it [00:44, 11.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "509it [00:44, 11.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "511it [00:45, 11.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "513it [00:45, 11.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "515it [00:45, 11.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "517it [00:45, 11.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "519it [00:45, 11.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "521it [00:45, 11.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "523it [00:46, 11.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "525it [00:46, 11.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "527it [00:46, 11.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "529it [00:46, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "531it [00:46, 11.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "533it [00:46, 11.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "535it [00:47, 11.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "537it [00:47, 11.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "539it [00:47, 11.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "541it [00:47, 11.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "543it [00:47, 11.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "545it [00:48, 11.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "547it [00:48, 11.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "549it [00:48, 11.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "551it [00:48, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "553it [00:48, 11.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "555it [00:48, 11.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "557it [00:49, 11.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "559it [00:49, 11.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "561it [00:49, 11.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "563it [00:49, 11.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "565it [00:49, 11.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "567it [00:49, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "569it [00:50, 11.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "571it [00:50, 11.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "573it [00:50, 11.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "575it [00:50, 11.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "577it [00:50, 11.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "579it [00:50, 12.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "581it [00:51, 11.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "583it [00:51, 11.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "585it [00:51, 11.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "587it [00:51, 11.90it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "train_model(model, centroids, criterion, optimizer, train_loader, val_loader, num_epochs=5, path_to_save=\"baseline_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
