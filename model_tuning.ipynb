{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zno22FtJPX9z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import get_mnist_dataset, get_data_loader\n",
    "#from utils import *\n",
    "#from models import *\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "from generate_dataloaders import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaJEVd0wPX94"
   },
   "source": [
    "## Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vi6hPzadPX95"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_filename,val_filename):\n",
    "    path = os.getcwd()\n",
    "    data_dir = path + '/data/'\n",
    "    train_dataloader = pkl.load(open(data_dir + train_filename,'rb'))\n",
    "    val_dataloader = pkl.load(open(data_dir + val_filename,'rb'))\n",
    "    return train_dataloader,val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLzh007PX98"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = path + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq-jDGFIPX99"
   },
   "outputs": [],
   "source": [
    "train_loader,val_loader = get_dataloaders('train_dataloader.p','val_dataloader.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tQEhYjtPX-A"
   },
   "outputs": [],
   "source": [
    "ground_truth_dataloader = pkl.load(open(data_dir + 'ground_truth_dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzz8lwNQPX-B",
    "outputId": "690cb77f-2525-4c5a-ea14-a162716e34d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "69-v6pTCPX-E"
   },
   "source": [
    "## Scratchwork (IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbzHfEqEPX-F",
    "outputId": "e190e666-75a9-43f4-881c-307d2e18993a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(train_loader):\n",
    "    print(len(x[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6foV2y9kPX-H",
    "outputId": "1201dae2-e377-4311-c1af-3527d5b632c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 5])\n",
      "tensor([[[1., 2., 3., 4., 5.],\n",
      "         [3., 3., 3., 3., 3.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [2., 1., 2., 1., 2.]],\n",
      "\n",
      "        [[0., 1., 0., 1., 0.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [2., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 2.]]])\n",
      "torch.Size([2])\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "minibatch = torch.tensor([\n",
    "                            [[1,2,3,4,5],[3,3,3,3,3],[1,1,1,1,1],[2,1,2,1,2]],\n",
    "                            [[0,1,0,1,0],[1,1,1,1,1],[2,0,0,0,0],[0,0,0,0,2]]\n",
    "                         ], dtype=torch.float32)\n",
    "\n",
    "flagged_indices = torch.tensor([1,2])\n",
    "\n",
    "upweight_value = 10\n",
    "\n",
    "print(minibatch.shape)\n",
    "print(minibatch)\n",
    "\n",
    "print(flagged_indices.shape)\n",
    "print(flagged_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrRatzhRPX-J",
    "outputId": "283ee2e9-6cd0-439b-a2db-2996aeda85fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "2 4 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [30., 30., 30., 30., 30.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.],\n",
       "         [ 2.,  1.,  2.,  1.,  2.]],\n",
       "\n",
       "        [[ 0.,  1.,  0.,  1.,  0.],\n",
       "         [ 1.,  1.,  1.,  1.,  1.],\n",
       "         [20.,  0.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  0.,  2.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_tokens, emb_dim = minibatch.shape\n",
    "print(type(minibatch))\n",
    "minibatch[range(batch_size),flagged_indices,:] *= upweight_value\n",
    "print(batch_size, num_tokens, emb_dim)\n",
    "minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3-0cZqzPX-K",
    "outputId": "9b9e9298-fc39-4fa3-cb20-94fc22dee9bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6154, 2.6154, 2.7692, 2.7692, 2.9231],\n",
       "        [1.6154, 0.1538, 0.0769, 0.1538, 0.2308]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch.sum(1) / (num_tokens + upweight_value - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFiD86rvPX-M",
    "outputId": "1f4c46ab-5c61-40fc-d9cb-30256b33acdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_xyk-TsdPX-O"
   },
   "outputs": [],
   "source": [
    "embed = torch.tensor(np.array([[2,4,5,6],[1,3,45,7],[3,4,5,6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paQ0ohcwPX-Q"
   },
   "outputs": [],
   "source": [
    "centers = torch.tensor(np.array(([2,3,4,5],[1,2,4,5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBKi1uXdPX-R",
    "outputId": "a5c9c793-4abb-4375-e0fb-13f56bef5718"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   3,    7],\n",
       "        [1686, 1686],\n",
       "        [   4,   10]])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((embed[:,None,:]-centers)**2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OZ2VcvBzPX-T",
    "outputId": "f2369f2c-a0f3-4b62-aa0d-ffc4e9ef7c22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_distances, cluster_assignments = torch.sum((embed[:,None,:]-centers)**2, 2).min(1)\n",
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OU5oKfrGPX-V",
    "outputId": "ace2c69a-d28e-444a-bc38-b1feead074dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   34,    19,  3042,   165,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1901,   257,   171,   664,    85,    41,  2684,    20,   519,   182,\n",
      "            41,   643,   214,   170,    30,    41,   958,  1789,   214,  8043,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 4418,    69,    60,   518,    11,    20,   216,    10,    84,     7,\n",
      "            18,  4419,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   68,   302,    60,  1207,  2449,   135,   398,    52,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  360,    20,    78,    20,   532,     7,   435,    44,     6,   135,\n",
      "         12914,    21,  5020,   361,    76,   135,   227,   427,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [10740,   156,    77,   207,     7,    77,   333,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,   784,    20,    34,    84,     7,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  165,   166,    20,   996,     7,  1331,    41,  1241,    29,    95,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  210,   880,     7,   165,    19,   121,   294,   194,   117, 13646,\n",
      "           227,   484,    60,   572,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   39,   302,    60,   609,   167,   876,    85,    71,   140,    34,\n",
      "           170,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   34,    19,    20,   401,  2722,   556,  2775,   294,    41,    16,\n",
      "           214,    19,   156,    34,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   37,    83,     7,    77,   210,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 1351,   383,    69,    34,     7,    77,   333,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   60,    34,    36,     7,   113,    14,    20,   157,   246,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,    38,    20,    30,    77,   250,   879,    95,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [ 7309,    69,    34,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   34,    38,   123,    77,    27,  1917,   123,    17,    77,   210,\n",
      "           166,    25,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [    3,   177,   593, 14301,    44,   759,    41,    38,   246,     7,\n",
      "           246,   157,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  365,   646,    20,    34,    51,    44,    52,    20,   142,  3038,\n",
      "           214,    36,   258,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   68,   302,    60,  1964,     7,  1597,   234,   214,  3341,     7,\n",
      "            41,  3342,    44,  1123,    41,   212,   156,    10,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  636,   366,  3407,    73,    99,   171,  1613,   113,   152,   241,\n",
      "           115,   214,   171,   412,   136,   139,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   34,   170,    20,    84,     7,  7956,    83,    29,    21,    22,\n",
      "            19,    30,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,    44,    19,    30,   123,    29,    21,    42,  1169,    24,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   73,    20,   310,     7,   333,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   34,    19,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  247,   165,    20,    77,   289,   214,   558,    20,    34,    30,\n",
      "           937,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   29,   117,   118,   171,    28,     4,  1309,   914,    20,     7,\n",
      "            29,   394,   163,   318,    30,    41,    19,   246,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   77,   230,     7,  1346,    44,    19,    30,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   34,    19,    20,     7,   210,   196,  1271,   741,  2468,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  163,   135,   167,     7,   163,   512,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   29,   156,   485,     4,   145,  9716,  9717,   464,     4,   199,\n",
      "           297,    20,   171,  6756,  1214,   214,    41,    36,   156,  9718,\n",
      "           356,  1352,   124,   214,    41,   601,   112,     0,     0,     0],\n",
      "        [   66,    19,  2057,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]) tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
      "        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]) tensor([ 0,  3,  7,  3,  6,  3,  0,  3,  1,  3, 13,  5,  1,  1,  0,  2,  0,  2,\n",
      "         3, 17,  3,  0,  0,  0,  0,  4,  4,  1,  0,  5, 13,  0])\n"
     ]
    }
   ],
   "source": [
    "for i, (tokens, labels, flagged_indices) in enumerate(train_loader):\n",
    "    print(tokens, labels, flagged_indices)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt6N9QCPX-X"
   },
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puweJhdxPX-Y"
   },
   "source": [
    "NOTE: Data loader is defined as:\n",
    "- tuple: (tokens, flagged_index, problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8BZ-QhNPX-Z"
   },
   "outputs": [],
   "source": [
    "class neuralNetBow(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n",
    "    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n",
    "    def __init__(self, vocab_size, emb_dim, upweight=10):\n",
    "        super(neuralNetBow, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=2)\n",
    "        self.upweight = upweight\n",
    "    \n",
    "    def forward(self, tokens, flagged_index):\n",
    "        batch_size, num_tokens = tokens.shape\n",
    "        embedding = self.embed(tokens)\n",
    "#         print(embedding.shape) # below assumes \"batch_size x num_tokens x Emb_dim\" (VERIFY)\n",
    "        \n",
    "        # upweight by flagged_index\n",
    "#         print(type(embedding))\n",
    "        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n",
    "        \n",
    "        # average across embeddings\n",
    "        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n",
    "        \n",
    "        return embedding_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGsqcnEtPX-a"
   },
   "source": [
    "### Clustering Stuff (un-tailored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrgIYm8JPX-b"
   },
   "outputs": [],
   "source": [
    "class KMeansCriterion(nn.Module):\n",
    "    \n",
    "    def __init__(self, lmbda):\n",
    "        super().__init__()\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def forward(self, embeddings, centroids):\n",
    "        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n",
    "        cluster_distances, cluster_assignments = distances.min(1)\n",
    "        loss = self.lmbda * cluster_distances.sum()\n",
    "        return loss, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJohK2aPX-d"
   },
   "outputs": [],
   "source": [
    "def centroid_init(k, d, dataloader, model, current_device):\n",
    "    ## Here we ideally don't want to do randomized/zero initialization\n",
    "    centroid_sums = torch.zeros(k, d).to(current_device)\n",
    "    centroid_counts = torch.zeros(k)\n",
    "    for (tokens, labels, flagged_indices) in dataloader:\n",
    "#         cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n",
    "        cluster_assignments = labels.to(current_device)\n",
    "        \n",
    "        model.eval()\n",
    "        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n",
    "    \n",
    "        update_clusters(centroid_sums, centroid_counts,\n",
    "                        cluster_assignments, sentence_embed.to(current_device))\n",
    "    \n",
    "    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n",
    "    return centroid_means.clone()\n",
    "\n",
    "def update_clusters(centroid_sums, centroid_counts,\n",
    "                    cluster_assignments, embeddings):\n",
    "    k = centroid_sums.size(0)\n",
    "\n",
    "    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n",
    "    np_cluster_assignments = cluster_assignments.to('cpu')\n",
    "    np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n",
    "    centroid_counts.add_(torch.FloatTensor(np_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3wynM7fPX-h"
   },
   "source": [
    "### Training Function (un-tailored, needs alterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KglsYxPJPX-i"
   },
   "outputs": [],
   "source": [
    "def train_model(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs=10, path_to_save=None, print_every = 100):\n",
    "\n",
    "    model.train()\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus > 0:\n",
    "        current_device = 'cuda'\n",
    "    else:\n",
    "        current_device = 'cpu'\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        k, d = centroids.size()\n",
    "        centroid_sums = torch.zeros_like(centroids)\n",
    "        centroid_counts = torch.zeros(k)\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "        # run one epoch of gradient descent on autoencoders wrt centroids\n",
    "        for i, (tokens, labels, flagged_indices) in tqdm(enumerate(train_loader)):\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "\n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n",
    "\n",
    "            # run update step\n",
    "            optimizer.zero_grad()\n",
    "            cluster_loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Add loss to the epoch loss\n",
    "            total_epoch_loss += cluster_loss.data\n",
    "\n",
    "            # store centroid sums and counts in memory for later centering\n",
    "            update_clusters(centroid_sums, centroid_counts,\n",
    "                            cluster_assignments, sentence_embed)\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                losses = cluster_loss.data/len(tokens)\n",
    "                print('Average training Loss at batch',i,': %.3f' % losses)\n",
    "                \n",
    "            \n",
    "        total_epoch_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        print('Average training Loss after epoch',epoch,': %.3f' % total_epoch_loss)\n",
    "\n",
    "        # update centroids based on assignments from autoencoders\n",
    "        centroids = centroid_sums / (centroid_counts[:, None] + 1).to(current_device)\n",
    "        \n",
    "    if path_to_save == None:\n",
    "        pass\n",
    "    else:\n",
    "        torch.save(model.state_dict(), path_to_save)\n",
    "        \n",
    "    return model, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0kEtvbqPX-k"
   },
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'vocab_size': 20000,\n",
    "    'emb_dim': 512\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pBet75ZPX-m"
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "\n",
    "model = neuralNetBow(opts['vocab_size'], opts['emb_dim']).to(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTFO2vp-PX-o"
   },
   "outputs": [],
   "source": [
    "# model = neuralNetBow(opts['vocab_size'], opts['emb_dim'])\n",
    "centroids = centroid_init(2, opts['emb_dim'],ground_truth_dataloader, model, current_device)\n",
    "criterion = KMeansCriterion(1).to(current_device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xya2NiqcPX-q",
    "outputId": "59b3072e-c567-4e18-a242-ba8298f08e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4438, -0.0525,  0.1054,  ...,  0.1595,  0.1759,  0.5402],\n",
       "        [ 0.3969, -0.0488,  0.1069,  ...,  0.2194,  0.1766,  0.5496]],\n",
       "       grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1573355494600,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 300
    },
    "id": "2It2SvzjPX-s",
    "outputId": "5de6949c-7e9e-4ade-f222-5eb28f5347db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8813,
     "status": "error",
     "timestamp": 1573355511003,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 300
    },
    "id": "rgwMd27mPX-u",
    "outputId": "063ebc41-be3c-4474-d92c-7bd0680bb366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 62.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 0 : 47.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:01, 97.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 100 : 26.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [00:02, 100.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 200 : 13.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321it [00:03, 100.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 300 : 11.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "417it [00:04, 99.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 400 : 8.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "511it [00:05, 99.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 500 : 11.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "618it [00:06, 99.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 600 : 7.249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "720it [00:07, 99.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training Loss at batch 700 : 4.272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "784it [00:07, 100.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-63b65fb17a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-dd4c3cba39a2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs, path_to_save, print_every)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# store centroid sums and counts in memory for later centering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             update_clusters(centroid_sums, centroid_counts,\n\u001b[0;32m---> 37\u001b[0;31m                             cluster_assignments, sentence_embed)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-fd546816f290>\u001b[0m in \u001b[0;36mupdate_clusters\u001b[0;34m(centroid_sums, centroid_counts, cluster_assignments, embeddings)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcentroid_sums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_assignments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnp_cluster_assignments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_assignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mnp_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_cluster_assignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcentroid_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, centroids, criterion, optimizer, train_loader, val_loader, \"baseline_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3MRmCyCPX-v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJlqoR0BPX-x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hl3mgp5GPX-z",
    "outputId": "b82c9618-a924-4f27-850c-9b9110d9dcd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2])\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UCb-1EIPX-3",
    "outputId": "31605a57-d05b-4705-cb3c-e9d050e27060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([2])\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UecIBWuePX-6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
