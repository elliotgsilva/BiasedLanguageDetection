{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"model_tuning.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MVzJulwVPeCs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"dd09becf-b648-4135-c26a-a83019b0f8e0","executionInfo":{"status":"ok","timestamp":1573354623307,"user_tz":300,"elapsed":21503,"user":{"displayName":"Eileen Cho","photoUrl":"","userId":"03381570147993013394"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T0-izhJmPprH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a0847d63-4b95-4117-844b-af9567f96344","executionInfo":{"status":"ok","timestamp":1573354649589,"user_tz":300,"elapsed":351,"user":{"displayName":"Eileen Cho","photoUrl":"","userId":"03381570147993013394"}}},"source":["%cd /content/drive/My Drive/2019 Fall/Capstone group"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/2019 Fall/Capstone group\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gvMghVAqPsG_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"30f8c63b-a399-424d-bd2d-0a593a947dff","executionInfo":{"status":"ok","timestamp":1573354661587,"user_tz":300,"elapsed":5043,"user":{"displayName":"Eileen Cho","photoUrl":"","userId":"03381570147993013394"}}},"source":["!pip install jsonlines"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting jsonlines\n","  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-1.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zno22FtJPX9z","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn\n","from torch import optim\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","#from datasets import get_mnist_dataset, get_data_loader\n","#from utils import *\n","#from models import *\n","\n","import pickle as pkl\n","import os\n","\n","from generate_dataloaders import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oaJEVd0wPX94","colab_type":"text"},"source":["## Get Dataloaders"]},{"cell_type":"code","metadata":{"id":"vi6hPzadPX95","colab_type":"code","colab":{}},"source":["def get_dataloaders(train_filename,val_filename):\n","    path = os.getcwd()\n","    data_dir = path + '/data/'\n","    train_dataloader = pkl.load(open(data_dir + train_filename,'rb'))\n","    val_dataloader = pkl.load(open(data_dir + val_filename,'rb'))\n","    return train_dataloader,val_dataloader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nLzh007PX98","colab_type":"code","colab":{}},"source":["path = os.getcwd()\n","data_dir = path + '/data/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yq-jDGFIPX99","colab_type":"code","colab":{}},"source":["train_loader,val_loader = get_dataloaders('train_dataloader.p','val_dataloader.p')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tQEhYjtPX-A","colab_type":"code","colab":{}},"source":["ground_truth_dataloader = pkl.load(open(data_dir + 'ground_truth_dataloader.p','rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lzz8lwNQPX-B","colab_type":"code","colab":{},"outputId":"690cb77f-2525-4c5a-ea14-a162716e34d3"},"source":["print(torch.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.3.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"69-v6pTCPX-E","colab_type":"text"},"source":["## Scratchwork (IGNORE)"]},{"cell_type":"code","metadata":{"id":"XbzHfEqEPX-F","colab_type":"code","colab":{},"outputId":"e190e666-75a9-43f4-881c-307d2e18993a"},"source":["for i,x in enumerate(train_loader):\n","    print(len(x[0]))\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6foV2y9kPX-H","colab_type":"code","colab":{},"outputId":"1201dae2-e377-4311-c1af-3527d5b632c7"},"source":["minibatch = torch.tensor([\n","                            [[1,2,3,4,5],[3,3,3,3,3],[1,1,1,1,1],[2,1,2,1,2]],\n","                            [[0,1,0,1,0],[1,1,1,1,1],[2,0,0,0,0],[0,0,0,0,2]]\n","                         ], dtype=torch.float32)\n","\n","flagged_indices = torch.tensor([1,2])\n","\n","upweight_value = 10\n","\n","print(minibatch.shape)\n","print(minibatch)\n","\n","print(flagged_indices.shape)\n","print(flagged_indices)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([2, 4, 5])\n","tensor([[[1., 2., 3., 4., 5.],\n","         [3., 3., 3., 3., 3.],\n","         [1., 1., 1., 1., 1.],\n","         [2., 1., 2., 1., 2.]],\n","\n","        [[0., 1., 0., 1., 0.],\n","         [1., 1., 1., 1., 1.],\n","         [2., 0., 0., 0., 0.],\n","         [0., 0., 0., 0., 2.]]])\n","torch.Size([2])\n","tensor([1, 2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LrRatzhRPX-J","colab_type":"code","colab":{},"outputId":"283ee2e9-6cd0-439b-a2db-2996aeda85fb"},"source":["batch_size, num_tokens, emb_dim = minibatch.shape\n","print(type(minibatch))\n","minibatch[range(batch_size),flagged_indices,:] *= upweight_value\n","print(batch_size, num_tokens, emb_dim)\n","minibatch"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","2 4 5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 1.,  2.,  3.,  4.,  5.],\n","         [30., 30., 30., 30., 30.],\n","         [ 1.,  1.,  1.,  1.,  1.],\n","         [ 2.,  1.,  2.,  1.,  2.]],\n","\n","        [[ 0.,  1.,  0.,  1.,  0.],\n","         [ 1.,  1.,  1.,  1.,  1.],\n","         [20.,  0.,  0.,  0.,  0.],\n","         [ 0.,  0.,  0.,  0.,  2.]]])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"q3-0cZqzPX-K","colab_type":"code","colab":{},"outputId":"9b9e9298-fc39-4fa3-cb20-94fc22dee9bd"},"source":["minibatch.sum(1) / (num_tokens + upweight_value - 1)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2.6154, 2.6154, 2.7692, 2.7692, 2.9231],\n","        [1.6154, 0.1538, 0.0769, 0.1538, 0.2308]])"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"TFiD86rvPX-M","colab_type":"code","colab":{},"outputId":"1f4c46ab-5c61-40fc-d9cb-30256b33acdb"},"source":["print(type(minibatch))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_xyk-TsdPX-O","colab_type":"code","colab":{}},"source":["embed = torch.tensor(np.array([[2,4,5,6],[1,3,45,7],[3,4,5,6]]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"paQ0ohcwPX-Q","colab_type":"code","colab":{}},"source":["centers = torch.tensor(np.array(([2,3,4,5],[1,2,4,5])))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBKi1uXdPX-R","colab_type":"code","colab":{},"outputId":"a5c9c793-4abb-4375-e0fb-13f56bef5718"},"source":["torch.sum((embed[:,None,:]-centers)**2,2)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[   3,    7],\n","        [1686, 1686],\n","        [   4,   10]])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"OZ2VcvBzPX-T","colab_type":"code","colab":{},"outputId":"f2369f2c-a0f3-4b62-aa0d-ffc4e9ef7c22"},"source":["cluster_distances, cluster_assignments = torch.sum((embed[:,None,:]-centers)**2, 2).min(1)\n","cluster_assignments"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"OU5oKfrGPX-V","colab_type":"code","colab":{},"outputId":"ace2c69a-d28e-444a-bc38-b1feead074dc"},"source":["for i, (tokens, labels, flagged_indices) in enumerate(train_loader):\n","    print(tokens, labels, flagged_indices)\n","    break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[   34,    19,  3042,   165,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [ 1901,   257,   171,   664,    85,    41,  2684,    20,   519,   182,\n","            41,   643,   214,   170,    30,    41,   958,  1789,   214,  8043,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [ 4418,    69,    60,   518,    11,    20,   216,    10,    84,     7,\n","            18,  4419,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   68,   302,    60,  1207,  2449,   135,   398,    52,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  360,    20,    78,    20,   532,     7,   435,    44,     6,   135,\n","         12914,    21,  5020,   361,    76,   135,   227,   427,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [10740,   156,    77,   207,     7,    77,   333,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   10,   784,    20,    34,    84,     7,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  165,   166,    20,   996,     7,  1331,    41,  1241,    29,    95,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  210,   880,     7,   165,    19,   121,   294,   194,   117, 13646,\n","           227,   484,    60,   572,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   39,   302,    60,   609,   167,   876,    85,    71,   140,    34,\n","           170,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   34,    19,    20,   401,  2722,   556,  2775,   294,    41,    16,\n","           214,    19,   156,    34,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   37,    83,     7,    77,   210,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [ 1351,   383,    69,    34,     7,    77,   333,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   60,    34,    36,     7,   113,    14,    20,   157,   246,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   10,    38,    20,    30,    77,   250,   879,    95,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [ 7309,    69,    34,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   34,    38,   123,    77,    27,  1917,   123,    17,    77,   210,\n","           166,    25,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [    3,   177,   593, 14301,    44,   759,    41,    38,   246,     7,\n","           246,   157,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  365,   646,    20,    34,    51,    44,    52,    20,   142,  3038,\n","           214,    36,   258,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   68,   302,    60,  1964,     7,  1597,   234,   214,  3341,     7,\n","            41,  3342,    44,  1123,    41,   212,   156,    10,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  636,   366,  3407,    73,    99,   171,  1613,   113,   152,   241,\n","           115,   214,   171,   412,   136,   139,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   34,   170,    20,    84,     7,  7956,    83,    29,    21,    22,\n","            19,    30,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   10,    44,    19,    30,   123,    29,    21,    42,  1169,    24,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   73,    20,   310,     7,   333,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   34,    19,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  247,   165,    20,    77,   289,   214,   558,    20,    34,    30,\n","           937,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   29,   117,   118,   171,    28,     4,  1309,   914,    20,     7,\n","            29,   394,   163,   318,    30,    41,    19,   246,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   77,   230,     7,  1346,    44,    19,    30,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   34,    19,    20,     7,   210,   196,  1271,   741,  2468,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  163,   135,   167,     7,   163,   512,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [   29,   156,   485,     4,   145,  9716,  9717,   464,     4,   199,\n","           297,    20,   171,  6756,  1214,   214,    41,    36,   156,  9718,\n","           356,  1352,   124,   214,    41,   601,   112,     0,     0,     0],\n","        [   66,    19,  2057,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]) tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n","        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]) tensor([ 0,  3,  7,  3,  6,  3,  0,  3,  1,  3, 13,  5,  1,  1,  0,  2,  0,  2,\n","         3, 17,  3,  0,  0,  0,  0,  4,  4,  1,  0,  5, 13,  0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cvt6N9QCPX-X","colab_type":"text"},"source":["## Neural Network Class"]},{"cell_type":"markdown","metadata":{"id":"puweJhdxPX-Y","colab_type":"text"},"source":["NOTE: Data loader is defined as:\n","- tuple: (tokens, flagged_index, problematic)"]},{"cell_type":"code","metadata":{"id":"W8BZ-QhNPX-Z","colab_type":"code","colab":{}},"source":["class neuralNetBow(nn.Module):\n","    \"\"\"\n","    BagOfWords classification model\n","    \"\"\"\n","    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n","    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n","    def __init__(self, vocab_size, emb_dim, upweight=10):\n","        super(neuralNetBow, self).__init__()\n","        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=2)\n","        self.upweight = upweight\n","    \n","    def forward(self, tokens, flagged_index):\n","        batch_size, num_tokens = tokens.shape\n","        embedding = self.embed(tokens)\n","#         print(embedding.shape) # below assumes \"batch_size x num_tokens x Emb_dim\" (VERIFY)\n","        \n","        # upweight by flagged_index\n","#         print(type(embedding))\n","        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n","        \n","        # average across embeddings\n","        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n","        \n","        return embedding_ave"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SGsqcnEtPX-a","colab_type":"text"},"source":["### Clustering Stuff (un-tailored)"]},{"cell_type":"code","metadata":{"id":"MrgIYm8JPX-b","colab_type":"code","colab":{}},"source":["class KMeansCriterion(nn.Module):\n","    \n","    def __init__(self, lmbda):\n","        super().__init__()\n","        self.lmbda = lmbda\n","    \n","    def forward(self, embeddings, centroids):\n","        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n","        cluster_distances, cluster_assignments = distances.min(1)\n","        loss = self.lmbda * cluster_distances.sum()\n","        return loss, cluster_assignments"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TJohK2aPX-d","colab_type":"code","colab":{}},"source":["def centroid_init(k, d, dataloader, model, current_device):\n","    ## Here we ideally don't want to do randomized/zero initialization\n","    centroid_sums = torch.zeros(k, d).to(current_device)\n","    centroid_counts = torch.zeros(k)\n","    for (tokens, labels, flagged_indices) in dataloader:\n","#         cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n","        cluster_assignments = labels.to(current_device)\n","        \n","        model.eval()\n","        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n","    \n","        update_clusters(centroid_sums, centroid_counts,\n","                        cluster_assignments, sentence_embed.to(current_device))\n","    \n","    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n","    return centroid_means.clone()\n","\n","def update_clusters(centroid_sums, centroid_counts,\n","                    cluster_assignments, embeddings):\n","    k = centroid_sums.size(0)\n","\n","    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n","    np_cluster_assignments = cluster_assignments.to('cpu')\n","    np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n","    centroid_counts.add_(torch.FloatTensor(np_counts))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u3wynM7fPX-h","colab_type":"text"},"source":["### Training Function (un-tailored, needs alterations)"]},{"cell_type":"code","metadata":{"id":"KglsYxPJPX-i","colab_type":"code","colab":{}},"source":["def train_model(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs=10, path_to_save=None, print_every = 100):\n","\n","    model.train()\n","    num_gpus = torch.cuda.device_count()\n","    if num_gpus > 0:\n","        current_device = 'cuda'\n","    else:\n","        current_device = 'cpu'\n","    \n","    \n","    for epoch in range(num_epochs):\n","        k, d = centroids.size()\n","        centroid_sums = torch.zeros_like(centroids)\n","        centroid_counts = torch.zeros(k)\n","        total_epoch_loss = 0\n","\n","        # run one epoch of gradient descent on autoencoders wrt centroids\n","        for i, (tokens, labels, flagged_indices) in tqdm(enumerate(train_loader)):\n","            tokens = tokens.to(current_device)\n","            labels = labels.to(current_device)\n","            flagged_indices = flagged_indices.to(current_device)\n","\n","            # forward pass and compute loss\n","            sentence_embed = model(tokens,flagged_indices)\n","            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n","\n","            # run update step\n","            optimizer.zero_grad()\n","            cluster_loss.backward(retain_graph=True)\n","            optimizer.step()\n","            \n","            #Add loss to the epoch loss\n","            total_epoch_loss += cluster_loss.data\n","\n","            # store centroid sums and counts in memory for later centering\n","            update_clusters(centroid_sums, centroid_counts,\n","                            cluster_assignments, sentence_embed)\n","\n","            if i % print_every == 0:\n","                losses = cluster_loss.data/len(tokens)\n","                print('Average training Loss at batch',i,': %.3f' % losses)\n","                \n","            \n","        total_epoch_loss /= len(train_loader.dataset)\n","        \n","        print('Average training Loss after epoch',epoch,': %.3f' % total_epoch_loss)\n","\n","        # update centroids based on assignments from autoencoders\n","        centroids = centroid_sums / (centroid_counts[:, None] + 1)\n","        \n","    if path_to_save == None:\n","        pass\n","    else:\n","        torch.save(model.state_dict(), path_to_save)\n","        \n","    return model, centroids"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0kEtvbqPX-k","colab_type":"code","colab":{}},"source":["opts = {\n","    'vocab_size': 20000,\n","    'emb_dim': 512\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0pBet75ZPX-m","colab_type":"code","colab":{}},"source":["num_gpus = torch.cuda.device_count()\n","if num_gpus > 0:\n","    current_device = 'cuda'\n","else:\n","    current_device = 'cpu'\n","\n","model = neuralNetBow(opts['vocab_size'], opts['emb_dim']).to(current_device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTFO2vp-PX-o","colab_type":"code","colab":{}},"source":["# model = neuralNetBow(opts['vocab_size'], opts['emb_dim'])\n","centroids = centroid_init(2, opts['emb_dim'],ground_truth_dataloader, model, current_device)\n","criterion = KMeansCriterion(1).to(current_device)\n","optimizer = torch.optim.Adam(model.parameters(), 0.01, amsgrad=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xya2NiqcPX-q","colab_type":"code","colab":{},"outputId":"59b3072e-c567-4e18-a242-ba8298f08e58"},"source":["centroids"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.4438, -0.0525,  0.1054,  ...,  0.1595,  0.1759,  0.5402],\n","        [ 0.3969, -0.0488,  0.1069,  ...,  0.2194,  0.1766,  0.5496]],\n","       grad_fn=<CloneBackward>)"]},"metadata":{"tags":[]},"execution_count":170}]},{"cell_type":"code","metadata":{"id":"2It2SvzjPX-s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5de6949c-7e9e-4ade-f222-5eb28f5347db","executionInfo":{"status":"ok","timestamp":1573355494600,"user_tz":300,"elapsed":892,"user":{"displayName":"Eileen Cho","photoUrl":"","userId":"03381570147993013394"}}},"source":["current_device"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"rgwMd27mPX-u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":460},"outputId":"063ebc41-be3c-4474-d92c-7bd0680bb366","executionInfo":{"status":"error","timestamp":1573355511003,"user_tz":300,"elapsed":8813,"user":{"displayName":"Eileen Cho","photoUrl":"","userId":"03381570147993013394"}}},"source":["train_model(model, centroids, criterion, optimizer, train_loader, val_loader, \"baseline_model.pth\")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["16it [00:00, 62.09it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 0 : 47.298\n"],"name":"stdout"},{"output_type":"stream","text":["118it [00:01, 97.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 100 : 26.517\n"],"name":"stdout"},{"output_type":"stream","text":["213it [00:02, 100.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 200 : 13.138\n"],"name":"stdout"},{"output_type":"stream","text":["321it [00:03, 100.11it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 300 : 11.977\n"],"name":"stdout"},{"output_type":"stream","text":["417it [00:04, 99.56it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 400 : 8.541\n"],"name":"stdout"},{"output_type":"stream","text":["511it [00:05, 99.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 500 : 11.519\n"],"name":"stdout"},{"output_type":"stream","text":["618it [00:06, 99.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 600 : 7.249\n"],"name":"stdout"},{"output_type":"stream","text":["720it [00:07, 99.18it/s]"],"name":"stderr"},{"output_type":"stream","text":["Average training Loss at batch 700 : 4.272\n"],"name":"stdout"},{"output_type":"stream","text":["784it [00:07, 100.13it/s]\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-63b65fb17a99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-dd4c3cba39a2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs, path_to_save, print_every)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# store centroid sums and counts in memory for later centering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             update_clusters(centroid_sums, centroid_counts,\n\u001b[0;32m---> 37\u001b[0;31m                             cluster_assignments, sentence_embed)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-fd546816f290>\u001b[0m in \u001b[0;36mupdate_clusters\u001b[0;34m(centroid_sums, centroid_counts, cluster_assignments, embeddings)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcentroid_sums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_assignments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnp_cluster_assignments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_assignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mnp_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_cluster_assignments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mcentroid_counts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"r3MRmCyCPX-v","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJlqoR0BPX-x","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hl3mgp5GPX-z","colab_type":"code","colab":{},"outputId":"b82c9618-a924-4f27-850c-9b9110d9dcd1"},"source":["x = torch.tensor([2])\n","print(type(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9UCb-1EIPX-3","colab_type":"code","colab":{},"outputId":"31605a57-d05b-4705-cb3c-e9d050e27060"},"source":["x = torch.Tensor([2])\n","print(type(x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UecIBWuePX-6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}