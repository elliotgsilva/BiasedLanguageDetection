{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## KAGGLE ONLY\n",
    "# from shutil import copyfile\n",
    "# copyfile(src=\"../input/inputs/generate_dataloaders.py\", dst=\"../working/generate_dataloaders.py\")\n",
    "# copyfile(src=\"../input/inputs/train_dataloader.p\", dst=\"../working/train_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/val_dataloader.p\", dst=\"../working/val_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/centroids_dataloader.p\", dst=\"../working/ground_truth_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/dictionary.p\", dst=\"../working/dictionary.p\")\n",
    "\n",
    "# copyfile(src=\"../input/input2/train_unlabeld_dataloader.p\", dst=\"../working/train_unlabelled_dataloader.p\")\n",
    "# copyfile(src=\"../input/input2/train_labeled_dataloader.p\", dst=\"../working/train_labelled_dataloader.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zno22FtJPX9z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/evaluation.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import get_mnist_dataset, get_data_loader\n",
    "#from utils import *\n",
    "#from models import *\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from generate_dataloaders import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import evaluation\n",
    "import importlib\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaJEVd0wPX94"
   },
   "source": [
    "## Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1029\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLzh007PX98"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = path + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq-jDGFIPX99"
   },
   "outputs": [],
   "source": [
    "train_loader = pkl.load(open(data_dir + 'train_dataloader.p','rb'))\n",
    "train_loader_labelled = pkl.load(open(data_dir + 'train_labeled_dataloader.p','rb'))\n",
    "train_loader_unlabelled = pkl.load(open(data_dir + 'train_unlabeled_dataloader.p','rb'))\n",
    "val_loader = pkl.load(open(data_dir + 'val_dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda install pytorch torchvision -c pytorch\n",
    "## if torch.__version__ is not 1.3.1, run this cell then restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzz8lwNQPX-B",
    "outputId": "690cb77f-2525-4c5a-ea14-a162716e34d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt6N9QCPX-X"
   },
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puweJhdxPX-Y"
   },
   "source": [
    "NOTE: Data loader is defined as:\n",
    "- tuple: (tokens, flagged_index, problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8BZ-QhNPX-Z"
   },
   "outputs": [],
   "source": [
    "class neuralNetBow(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n",
    "    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n",
    "    def __init__(self, opts):\n",
    "        super(neuralNetBow, self).__init__()\n",
    "        self.embed = nn.Embedding(opts['vocab_size'], opts['emb_dim'], padding_idx=0)\n",
    "        self.upweight = opts['upweight']\n",
    "    \n",
    "    def forward(self, tokens, flagged_index):\n",
    "        batch_size, num_tokens = tokens.shape\n",
    "        embedding = self.embed(tokens)\n",
    "        \n",
    "        # upweight by flagged_index\n",
    "        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n",
    "        \n",
    "        # average across embeddings\n",
    "        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n",
    "        \n",
    "        return embedding_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGsqcnEtPX-a"
   },
   "source": [
    "### Clustering Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrgIYm8JPX-b"
   },
   "outputs": [],
   "source": [
    "class KMeansCriterion(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, embeddings, centroids):\n",
    "        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n",
    "        cluster_distances, cluster_assignments = distances.min(1)\n",
    "        loss = cluster_distances.sum()\n",
    "        return loss, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJohK2aPX-d"
   },
   "outputs": [],
   "source": [
    "def centroid_init(k, d, dataloader, model, current_device):\n",
    "    ## Here we ideally don't want to do randomized/zero initialization\n",
    "    centroid_sums = torch.zeros(k, d).to(current_device)\n",
    "    centroid_counts = torch.zeros(k).to(current_device)\n",
    "    for (tokens, labels, flagged_indices) in dataloader:\n",
    "        # cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n",
    "        cluster_assignments = labels.to(current_device)\n",
    "        \n",
    "        model.eval()\n",
    "        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n",
    "    \n",
    "        update_clusters(centroid_sums, centroid_counts,\n",
    "                        cluster_assignments, sentence_embed.to(current_device))\n",
    "    \n",
    "    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n",
    "    return centroid_means.clone()\n",
    "\n",
    "def update_clusters(centroid_sums, centroid_counts,\n",
    "                    cluster_assignments, embeddings):\n",
    "    k = centroid_sums.size(0)\n",
    "\n",
    "    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n",
    "    bin_counts = torch.bincount(cluster_assignments,minlength=k).type(torch.FloatTensor).to(current_device)\n",
    "    centroid_counts.add_(bin_counts)\n",
    "    \n",
    "    #np_cluster_assignments = cluster_assignments.to('cpu')\n",
    "    #np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n",
    "    #centroid_counts.add_(torch.FloatTensor(np_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3wynM7fPX-h"
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KglsYxPJPX-i"
   },
   "outputs": [],
   "source": [
    "def train_model(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs=10, path_to_save=None, print_every = 1000):\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus > 0:\n",
    "        current_device = 'cuda'\n",
    "    else:\n",
    "        current_device = 'cpu'\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('{} | Epoch {}'.format(dt.datetime.now(), epoch))\n",
    "        model.train()\n",
    "        k, d = centroids.size()\n",
    "        centroid_sums = torch.zeros_like(centroids).to(current_device)\n",
    "        centroid_counts = torch.zeros(k).to(current_device)\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "        # run one epoch of gradient descent on autoencoders wrt centroids\n",
    "        for i, (tokens, labels, flagged_indices) in tqdm(enumerate(train_loader)):\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "\n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids.detach())\n",
    "\n",
    "            # run update step\n",
    "            optimizer.zero_grad()\n",
    "            cluster_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Add loss to the epoch loss\n",
    "            total_epoch_loss += cluster_loss.data\n",
    "\n",
    "            # store centroid sums and counts in memory for later centering\n",
    "            update_clusters(centroid_sums, centroid_counts,\n",
    "                            cluster_assignments, sentence_embed)\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                losses = cluster_loss.data/len(tokens)\n",
    "                print('Average training loss at batch ',i,': %.3f' % losses)\n",
    "            \n",
    "        total_epoch_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(total_epoch_loss)\n",
    "        print('Average training loss after epoch ',epoch,': %.3f' % total_epoch_loss)\n",
    "        \n",
    "        # update centroids based on assignments from autoencoders\n",
    "        centroids = centroid_sums / (centroid_counts[:, None] + 1).to(current_device)\n",
    "        \n",
    "        # calculate validation loss after every epoch\n",
    "        total_validation_loss = 0\n",
    "        for i, (tokens, labels, flagged_indices) in enumerate(valid_loader):\n",
    "            model.eval()\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "            \n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n",
    "            \n",
    "            #Add loss to the validation loss\n",
    "            total_validation_loss += cluster_loss.data\n",
    "\n",
    "        total_validation_loss /= len(valid_loader.dataset)\n",
    "        val_losses.append(total_validation_loss)\n",
    "        print('Average validation loss after epoch ',epoch,': %.3f' % total_validation_loss)\n",
    "        \n",
    "        if path_to_save == None:\n",
    "            pass\n",
    "        else:\n",
    "            torch.save(model.state_dict(), path_to_save+'model_dict.pt')\n",
    "            torch.save(centroids, path_to_save+'centroids')\n",
    "            torch.save(train_losses, path_to_save+'train_losses')\n",
    "            torch.save(val_losses, path_to_save+'val_losses')\n",
    "            torch.save(opts, path_to_save+'opts') #change options depending on model inputs required\n",
    "        \n",
    "    return model, centroids, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pBet75ZPX-m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: cpu\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "print(\"Current Device:\",current_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_directory(opts):\n",
    "    path = os.getcwd()\n",
    "    model_folder = 'baseline_randomized_embeddings/'\n",
    "    model_dir = path + '/models/' + model_folder\n",
    "    \n",
    "    # subfolder for each hyperparam config\n",
    "    emb_dim = opts['emb_dim']\n",
    "    upweight = opts['upweight']\n",
    "    subfolder = \"emb_dim=\"+str(emb_dim) + \",upweight=\"+str(upweight) + '/'\n",
    "    \n",
    "    # need to actually create these subfolders lol\n",
    "    try:\n",
    "        os.makedirs(model_dir + subfolder) # will throw error if subfolder already exists\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model_dir + subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config(opts):\n",
    "    model = neuralNetBow(opts).to(current_device)\n",
    "    centroids = centroid_init(2, opts['emb_dim'],train_loader_labelled, model, current_device)\n",
    "    criterion = KMeansCriterion().to(current_device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.01, amsgrad=True)\n",
    "    path_to_save = get_save_directory(opts)\n",
    "    print(path_to_save)\n",
    "    \n",
    "    train_model(model, centroids, criterion, optimizer, train_loader, val_loader, num_epochs=10, path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0kEtvbqPX-k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/emb_dim=256,upweight=1/\n",
      "2019-12-05 00:50:43.401612 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba7b9c24ac24ccdba4805a4c5c80d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 2.487\n",
      "Average training loss at batch  1000 : 0.218\n",
      "Average training loss at batch  2000 : 0.127\n",
      "Average training loss at batch  3000 : 0.148\n",
      "\n",
      "Average training loss after epoch  0 : 0.364\n",
      "Average validation loss after epoch  0 : 0.121\n",
      "2019-12-05 00:53:15.382962 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176f625850d14b6da2c7109f24a64fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.095\n",
      "Average training loss at batch  1000 : 0.059\n",
      "Average training loss at batch  2000 : 0.061\n",
      "Average training loss at batch  3000 : 0.055\n",
      "\n",
      "Average training loss after epoch  1 : 0.074\n",
      "Average validation loss after epoch  1 : 0.075\n",
      "2019-12-05 00:56:20.976297 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e33e0884ef4a0d961d264c615970d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.043\n",
      "Average training loss at batch  1000 : 0.041\n",
      "Average training loss at batch  2000 : 0.056\n",
      "Average training loss at batch  3000 : 0.040\n",
      "\n",
      "Average training loss after epoch  2 : 0.045\n",
      "Average validation loss after epoch  2 : 0.058\n",
      "2019-12-05 00:59:25.675293 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14eb052258c84992b7cba37403124392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.032\n",
      "Average training loss at batch  1000 : 0.034\n",
      "Average training loss at batch  2000 : 0.040\n",
      "Average training loss at batch  3000 : 0.030\n",
      "\n",
      "Average training loss after epoch  3 : 0.033\n",
      "Average validation loss after epoch  3 : 0.052\n",
      "2019-12-05 01:02:30.942499 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6791db4ea20a452e9d3da7a111eced42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.018\n",
      "Average training loss at batch  1000 : 0.023\n",
      "Average training loss at batch  2000 : 0.022\n",
      "Average training loss at batch  3000 : 0.030\n",
      "\n",
      "Average training loss after epoch  4 : 0.026\n",
      "Average validation loss after epoch  4 : 0.044\n",
      "2019-12-05 01:05:35.669082 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730052bb5f53408ab18950dbeb44820f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.017\n",
      "Average training loss at batch  1000 : 0.019\n",
      "Average training loss at batch  2000 : 0.018\n",
      "Average training loss at batch  3000 : 0.021\n",
      "\n",
      "Average training loss after epoch  5 : 0.021\n",
      "Average validation loss after epoch  5 : 0.039\n",
      "2019-12-05 01:08:41.817451 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727b0907c6e44d6b854ab7c4e373fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.013\n",
      "Average training loss at batch  1000 : 0.017\n",
      "Average training loss at batch  2000 : 0.012\n",
      "Average training loss at batch  3000 : 0.014\n",
      "\n",
      "Average training loss after epoch  6 : 0.016\n",
      "Average validation loss after epoch  6 : 0.033\n",
      "2019-12-05 01:11:46.367662 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b0b5925477454095e8c30510fd0df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.017\n",
      "Average training loss at batch  1000 : 0.012\n",
      "Average training loss at batch  2000 : 0.009\n",
      "Average training loss at batch  3000 : 0.011\n",
      "\n",
      "Average training loss after epoch  7 : 0.011\n",
      "Average validation loss after epoch  7 : 0.030\n",
      "2019-12-05 01:14:50.510008 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4b36caf4174d3c98f8765d8aa10fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.006\n",
      "Average training loss at batch  1000 : 0.007\n",
      "Average training loss at batch  2000 : 0.007\n",
      "Average training loss at batch  3000 : 0.010\n",
      "\n",
      "Average training loss after epoch  8 : 0.009\n",
      "Average validation loss after epoch  8 : 0.029\n",
      "2019-12-05 01:17:52.398999 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7237c59f9543a4b1af616ec4703445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.008\n",
      "Average training loss at batch  1000 : 0.007\n",
      "Average training loss at batch  2000 : 0.007\n",
      "Average training loss at batch  3000 : 0.009\n",
      "\n",
      "Average training loss after epoch  9 : 0.008\n",
      "Average validation loss after epoch  9 : 0.028\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/emb_dim=256,upweight=5/\n",
      "2019-12-05 01:21:05.218592 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f35c37da7c4f7fa6226d9b202e9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 6.543\n",
      "Average training loss at batch  1000 : 0.250\n",
      "Average training loss at batch  2000 : 0.183\n",
      "Average training loss at batch  3000 : 0.084\n",
      "\n",
      "Average training loss after epoch  0 : 0.533\n",
      "Average validation loss after epoch  0 : 0.115\n",
      "2019-12-05 01:23:37.590837 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc9fb51073b462c801ac3f2419f5e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.078\n",
      "Average training loss at batch  1000 : 0.041\n",
      "Average training loss at batch  2000 : 0.052\n",
      "Average training loss at batch  3000 : 0.057\n",
      "\n",
      "Average training loss after epoch  1 : 0.059\n",
      "Average validation loss after epoch  1 : 0.062\n",
      "2019-12-05 01:26:40.250986 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5e2a477c994a43aa0381ffe4854eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.031\n",
      "Average training loss at batch  1000 : 0.021\n",
      "Average training loss at batch  2000 : 0.035\n",
      "Average training loss at batch  3000 : 0.026\n",
      "\n",
      "Average training loss after epoch  2 : 0.031\n",
      "Average validation loss after epoch  2 : 0.047\n",
      "2019-12-05 01:29:45.774322 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d08d37be4e4f37bdb618b9b6fcd4d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.026\n",
      "Average training loss at batch  1000 : 0.030\n",
      "Average training loss at batch  2000 : 0.018\n",
      "Average training loss at batch  3000 : 0.016\n",
      "\n",
      "Average training loss after epoch  3 : 0.021\n",
      "Average validation loss after epoch  3 : 0.040\n",
      "2019-12-05 01:32:52.299282 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea1a8ac684844116992a7ec27535f1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.012\n",
      "Average training loss at batch  1000 : 0.020\n",
      "Average training loss at batch  2000 : 0.016\n",
      "Average training loss at batch  3000 : 0.021\n",
      "\n",
      "Average training loss after epoch  4 : 0.016\n",
      "Average validation loss after epoch  4 : 0.035\n",
      "2019-12-05 01:35:59.302927 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65005b132b8348408091836bd397869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.012\n",
      "Average training loss at batch  1000 : 0.009\n",
      "Average training loss at batch  2000 : 0.016\n",
      "Average training loss at batch  3000 : 0.015\n",
      "\n",
      "Average training loss after epoch  5 : 0.013\n",
      "Average validation loss after epoch  5 : 0.033\n",
      "2019-12-05 01:39:03.540598 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9891732a76e742a1b1efce4b434eced5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.010\n",
      "Average training loss at batch  1000 : 0.016\n",
      "Average training loss at batch  2000 : 0.013\n",
      "Average training loss at batch  3000 : 0.007\n",
      "\n",
      "Average training loss after epoch  6 : 0.011\n",
      "Average validation loss after epoch  6 : 0.031\n",
      "2019-12-05 01:42:07.701699 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc7b7b5ccc640bea4a35dfa3f4e11c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.009\n",
      "Average training loss at batch  1000 : 0.009\n",
      "Average training loss at batch  2000 : 0.008\n",
      "Average training loss at batch  3000 : 0.012\n",
      "\n",
      "Average training loss after epoch  7 : 0.010\n",
      "Average validation loss after epoch  7 : 0.029\n",
      "2019-12-05 01:45:06.182514 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dec0e8f17c34ceea85154696445aabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.011\n",
      "Average training loss at batch  1000 : 0.008\n",
      "Average training loss at batch  2000 : 0.012\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  8 : 0.009\n",
      "Average validation loss after epoch  8 : 0.028\n",
      "2019-12-05 01:48:04.354277 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9863f0376dc4be7835fe0380673934a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.014\n",
      "Average training loss at batch  1000 : 0.011\n",
      "Average training loss at batch  2000 : 0.007\n",
      "Average training loss at batch  3000 : 0.010\n",
      "\n",
      "Average training loss after epoch  9 : 0.009\n",
      "Average validation loss after epoch  9 : 0.028\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/emb_dim=256,upweight=10/\n",
      "2019-12-05 01:51:20.141202 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe2b1fc7cb744deb175bb59d7dd88c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 13.405\n",
      "Average training loss at batch  1000 : 0.823\n",
      "Average training loss at batch  2000 : 0.203\n",
      "Average training loss at batch  3000 : 0.185\n",
      "\n",
      "Average training loss after epoch  0 : 0.970\n",
      "Average validation loss after epoch  0 : 0.151\n",
      "2019-12-05 01:53:49.715792 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b357e17557b43edb101b2b4706f8ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.055\n",
      "Average training loss at batch  1000 : 0.030\n",
      "Average training loss at batch  2000 : 0.039\n",
      "Average training loss at batch  3000 : 0.056\n",
      "\n",
      "Average training loss after epoch  1 : 0.073\n",
      "Average validation loss after epoch  1 : 0.075\n",
      "2019-12-05 01:56:50.252297 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489822b8b81e41219680f1b2e4bb633c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.072\n",
      "Average training loss at batch  1000 : 0.031\n",
      "Average training loss at batch  2000 : 0.025\n",
      "Average training loss at batch  3000 : 0.033\n",
      "\n",
      "Average training loss after epoch  2 : 0.034\n",
      "Average validation loss after epoch  2 : 0.055\n",
      "2019-12-05 01:59:56.619216 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1739b5087c4ed5af5edc694ffa5424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.015\n",
      "Average training loss at batch  1000 : 0.019\n",
      "Average training loss at batch  2000 : 0.013\n",
      "Average training loss at batch  3000 : 0.015\n",
      "\n",
      "Average training loss after epoch  3 : 0.021\n",
      "Average validation loss after epoch  3 : 0.047\n",
      "2019-12-05 02:03:09.825990 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a13fa19b054c918290051242b99595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.016\n",
      "Average training loss at batch  1000 : 0.014\n",
      "Average training loss at batch  2000 : 0.009\n",
      "Average training loss at batch  3000 : 0.016\n",
      "\n",
      "Average training loss after epoch  4 : 0.015\n",
      "Average validation loss after epoch  4 : 0.040\n",
      "2019-12-05 02:06:11.564302 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2353b4e94c402ebf2f4c43b67d25aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.008\n",
      "Average training loss at batch  1000 : 0.008\n",
      "Average training loss at batch  2000 : 0.014\n",
      "Average training loss at batch  3000 : 0.011\n",
      "\n",
      "Average training loss after epoch  5 : 0.012\n",
      "Average validation loss after epoch  5 : 0.037\n",
      "2019-12-05 02:09:17.791549 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4582204043454744902a66ffb913368c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.009\n",
      "Average training loss at batch  1000 : 0.010\n",
      "Average training loss at batch  2000 : 0.008\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  6 : 0.010\n",
      "Average validation loss after epoch  6 : 0.035\n",
      "2019-12-05 02:12:24.788187 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41b3688a0154e7ca3b9427fbde9dbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.010\n",
      "Average training loss at batch  1000 : 0.004\n",
      "Average training loss at batch  2000 : 0.007\n",
      "Average training loss at batch  3000 : 0.007\n",
      "\n",
      "Average training loss after epoch  7 : 0.008\n",
      "Average validation loss after epoch  7 : 0.033\n",
      "2019-12-05 02:15:39.514468 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5563497619a24c90b7f98f976428e491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.006\n",
      "Average training loss at batch  1000 : 0.007\n",
      "Average training loss at batch  2000 : 0.005\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  8 : 0.007\n",
      "Average validation loss after epoch  8 : 0.031\n",
      "2019-12-05 02:18:40.874285 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f0726a72004e8199bed15642f7e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.006\n",
      "Average training loss at batch  1000 : 0.005\n",
      "Average training loss at batch  2000 : 0.005\n",
      "Average training loss at batch  3000 : 0.005\n",
      "\n",
      "Average training loss after epoch  9 : 0.006\n",
      "Average validation loss after epoch  9 : 0.030\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/emb_dim=256,upweight=25/\n",
      "2019-12-05 02:21:49.946913 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f08d8e7a279473f98054cae3d3c3ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 45.360\n",
      "Average training loss at batch  1000 : 1.260\n",
      "Average training loss at batch  2000 : 0.182\n",
      "Average training loss at batch  3000 : 0.132\n",
      "\n",
      "Average training loss after epoch  0 : 2.445\n",
      "Average validation loss after epoch  0 : 0.282\n",
      "2019-12-05 02:24:26.207363 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e929742fd944b1cb4d3c6d9b5e5bbd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.080\n",
      "Average training loss at batch  1000 : 0.097\n",
      "Average training loss at batch  2000 : 0.051\n",
      "Average training loss at batch  3000 : 0.074\n",
      "\n",
      "Average training loss after epoch  1 : 0.129\n",
      "Average validation loss after epoch  1 : 0.143\n",
      "2019-12-05 02:27:42.777472 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2d62e7deb34e84a00e70c9ae3a9a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.038\n",
      "Average training loss at batch  1000 : 0.035\n",
      "Average training loss at batch  2000 : 0.021\n",
      "Average training loss at batch  3000 : 0.036\n",
      "\n",
      "Average training loss after epoch  2 : 0.056\n",
      "Average validation loss after epoch  2 : 0.106\n",
      "2019-12-05 02:30:53.872588 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e003863ae05a40f4a034b3622a6f93ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.023\n",
      "Average training loss at batch  1000 : 0.016\n",
      "Average training loss at batch  2000 : 0.020\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  3 : 0.032\n",
      "Average validation loss after epoch  3 : 0.089\n",
      "2019-12-05 02:34:00.571854 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d000851ba24e87beca96666e01cdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.009\n",
      "Average training loss at batch  1000 : 0.015\n",
      "Average training loss at batch  2000 : 0.019\n",
      "Average training loss at batch  3000 : 0.009\n",
      "\n",
      "Average training loss after epoch  4 : 0.021\n",
      "Average validation loss after epoch  4 : 0.079\n",
      "2019-12-05 02:37:06.877762 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c8c3fa315f4418ba38c5e000f8d8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.012\n",
      "Average training loss at batch  1000 : 0.015\n",
      "Average training loss at batch  2000 : 0.013\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  5 : 0.015\n",
      "Average validation loss after epoch  5 : 0.072\n",
      "2019-12-05 02:40:14.118881 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca5e55165df47dfaa8dabcd1536f87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.007\n",
      "Average training loss at batch  1000 : 0.010\n",
      "Average training loss at batch  2000 : 0.007\n",
      "Average training loss at batch  3000 : 0.006\n",
      "\n",
      "Average training loss after epoch  6 : 0.011\n",
      "Average validation loss after epoch  6 : 0.067\n",
      "2019-12-05 02:43:15.769398 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11aa5981d5e4a15bade151ddd807dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.006\n",
      "Average training loss at batch  1000 : 0.006\n",
      "Average training loss at batch  2000 : 0.008\n",
      "Average training loss at batch  3000 : 0.008\n",
      "\n",
      "Average training loss after epoch  7 : 0.009\n",
      "Average validation loss after epoch  7 : 0.062\n",
      "2019-12-05 02:46:24.206630 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776137d720cd474085d4e2d560410d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.005\n",
      "Average training loss at batch  1000 : 0.010\n",
      "Average training loss at batch  2000 : 0.008\n",
      "Average training loss at batch  3000 : 0.007\n",
      "\n",
      "Average training loss after epoch  8 : 0.007\n",
      "Average validation loss after epoch  8 : 0.059\n",
      "2019-12-05 02:49:32.862474 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16feb7016c584ab699dfec9993c394a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.007\n",
      "Average training loss at batch  1000 : 0.006\n",
      "Average training loss at batch  2000 : 0.052\n",
      "Average training loss at batch  3000 : 0.005\n",
      "\n",
      "Average training loss after epoch  9 : 0.006\n",
      "Average validation loss after epoch  9 : 0.057\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/emb_dim=512,upweight=1/\n",
      "2019-12-05 02:52:44.667335 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e85fe85069542389028a70fe71ce8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 6.285\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f8e9eaf9e2ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m'upweight'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         }\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-484074a817c4>\u001b[0m in \u001b[0;36mtrain_config\u001b[0;34m(opts)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-418ae6a5fa49>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, centroids, criterion, optimizer, train_loader, valid_loader, num_epochs, path_to_save, print_every)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcluster_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m#Add loss to the epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#emb_dims = [256, 512, 1024]\n",
    "emb_dims = [512, 1024]\n",
    "upweights = [1, 5, 10, 25]\n",
    "\n",
    "for emb_dim in emb_dims:\n",
    "    for upweight in upweights:\n",
    "        opts = {\n",
    "            'vocab_size': 20000,\n",
    "            'emb_dim': emb_dim,\n",
    "            'upweight': upweight\n",
    "        }\n",
    "        train_config(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8813,
     "status": "error",
     "timestamp": 1573355511003,
     "user": {
      "displayName": "Eileen Cho",
      "photoUrl": "",
      "userId": "03381570147993013394"
     },
     "user_tz": 300
    },
    "id": "rgwMd27mPX-u",
    "outputId": "063ebc41-be3c-4474-d92c-7bd0680bb366",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#baseline_model, baseline_centroids, baseline_train_losses, baseline_val_losses = train_model(model, centroids, criterion, optimizer, train_loader, val_loader, num_epochs=10, path_to_save=model_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell will change for each model\n",
    "model_folder = 'baseline_randomized_embeddings/'\n",
    "\n",
    "criterion = KMeansCriterion()\n",
    "criterion = criterion.to(current_device)\n",
    "\n",
    "#load model\n",
    "path = os.getcwd()\n",
    "model_dir = path + '/models/' + model_folder\n",
    "\n",
    "opts = torch.load(model_dir+'opts')\n",
    "model = neuralNetBow(opts['vocab_size'], opts['emb_dim']) #change according to model inputs\n",
    "model.load_state_dict(torch.load(model_dir+'model_dict.pt',map_location=lambda storage, loc: storage))\n",
    "model = model.to(current_device)\n",
    "centroids = torch.load(model_dir+'centroids',map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples in val loader: 455\n",
      "Assigned to cluster 1: 227\n",
      "TP_rate: 0.9779735682819384\n",
      "FP_rate: 0.022026431718061675\n",
      "FN_rate: 0.7763157894736842\n",
      "TN_rate: 0.2236842105263158\n",
      "\n",
      "\n",
      "Accuracy: 0.6008288894041272\n",
      "Precision: 0.9779735682819384\n",
      "Recall: 0.5574756319180573\n",
      "F1 score: 0.7101458425405646\n"
     ]
    }
   ],
   "source": [
    "TP_cluster, FP_cluster=evaluation.main(model, centroids, val_loader, criterion, data_dir, current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>index</th>\n",
       "      <th>flagged_word</th>\n",
       "      <th>assignment</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>strong ability to execute feedback with great artistic vision .</td>\n",
       "      <td>6</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>listened and created a great looking logo for us .</td>\n",
       "      <td>4</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>james did really great and went to great lengths to get it right for me .</td>\n",
       "      <td>7</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>great work .</td>\n",
       "      <td>0</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>great and fast solution for my posgresql question</td>\n",
       "      <td>0</td>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         review  \\\n",
       "35   strong ability to execute feedback with great artistic vision .              \n",
       "38   listened and created a great looking logo for us .                           \n",
       "97   james did really great and went to great lengths to get it right for me .    \n",
       "212  great work .                                                                 \n",
       "339  great and fast solution for my posgresql question                            \n",
       "\n",
       "     index flagged_word  assignment  original  \n",
       "35   6      great        1           0         \n",
       "38   4      great        1           0         \n",
       "97   7      great        1           0         \n",
       "212  0      great        1           0         \n",
       "339  0      great        1           0         "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_cluster[TP_cluster.original == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>index</th>\n",
       "      <th>flagged_word</th>\n",
       "      <th>assignment</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>working with ossobko visual was easy , all my vague requests and comments were immediately taken into account .</td>\n",
       "      <td>9</td>\n",
       "      <td>vague</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>great professionalism by this company , excellent project management skills</td>\n",
       "      <td>1</td>\n",
       "      <td>professionalism</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>it 's a pleasure to collaborate with him !</td>\n",
       "      <td>5</td>\n",
       "      <td>collaborate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wilndr understood my description to communicate my brand in the logo design .</td>\n",
       "      <td>5</td>\n",
       "      <td>communicate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fantastic designer , easy to work with , made changes to models without complaint .</td>\n",
       "      <td>11</td>\n",
       "      <td>models</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>excellent experience !</td>\n",
       "      <td>1</td>\n",
       "      <td>experience</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>i have enjoyed working with chris and he has helped me to implement and strategize difficult and challenging situations .</td>\n",
       "      <td>15</td>\n",
       "      <td>difficult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>nice results !</td>\n",
       "      <td>0</td>\n",
       "      <td>nice</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>the first submission i received was the eventual winner , with only minor changes suggested by me .</td>\n",
       "      <td>8</td>\n",
       "      <td>winner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>feel confident in choosing freshinnet ! !</td>\n",
       "      <td>0</td>\n",
       "      <td>feel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>dayalmodal3322 ( d ) provided the winning submission to my contest .</td>\n",
       "      <td>6</td>\n",
       "      <td>winning</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>so grateful to have giorgia on my team .</td>\n",
       "      <td>1</td>\n",
       "      <td>grateful</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>i feel very fortunate to have found id design team .</td>\n",
       "      <td>1</td>\n",
       "      <td>feel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>a pleasure to work with you james and we will be doing lots together going forward .</td>\n",
       "      <td>13</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>syakuro was the contest winner for our brand label and packing design challenge .</td>\n",
       "      <td>4</td>\n",
       "      <td>winner</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>cheers</td>\n",
       "      <td>0</td>\n",
       "      <td>cheers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>he is able to bring characters to life and make them feel real .</td>\n",
       "      <td>11</td>\n",
       "      <td>feel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>i am very happy with all that transpired between the design firm and the winning artist , alicia .</td>\n",
       "      <td>11</td>\n",
       "      <td>firm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>very pleased with initial work and looking forward to working together again .</td>\n",
       "      <td>10</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>delivered the task on time .</td>\n",
       "      <td>2</td>\n",
       "      <td>task</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>great experience , thanks .</td>\n",
       "      <td>1</td>\n",
       "      <td>experience</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>i have tried to resolve the issue with naren but have not been able to .</td>\n",
       "      <td>13</td>\n",
       "      <td>able</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>the design concepts created by this artist were instant favorites among the great competition .</td>\n",
       "      <td>13</td>\n",
       "      <td>competition</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>perfect understanding of the project , quick to complete and very good quality report .</td>\n",
       "      <td>1</td>\n",
       "      <td>understanding</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>great communication but my job could not be completed due to technical situation</td>\n",
       "      <td>11</td>\n",
       "      <td>technical</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>unreal attention to detail and response time .</td>\n",
       "      <td>5</td>\n",
       "      <td>response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>the first logo has been a hit , and the second will be too .</td>\n",
       "      <td>13</td>\n",
       "      <td>too</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>excellent job in putting together what i envisioned .</td>\n",
       "      <td>4</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>this is my second order and will order again .</td>\n",
       "      <td>4</td>\n",
       "      <td>order</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>he took a vague concept and crafted a perfect logo for what we were looking for .</td>\n",
       "      <td>3</td>\n",
       "      <td>vague</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>nick is amazingly knowledgeable in seo , and helped me better understand how my competitors were acquiring links and improving their search visibility .</td>\n",
       "      <td>11</td>\n",
       "      <td>understand</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>i will definitely work with them again and look forward to continuing work and building a good working relationship .</td>\n",
       "      <td>18</td>\n",
       "      <td>relationship</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>even after lack of contact on my part , he was prompt in assisting me and making whatever changes i asked .</td>\n",
       "      <td>13</td>\n",
       "      <td>assisting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>will be working together in the future and am happy to have found them !</td>\n",
       "      <td>3</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>so pleased with my experience !</td>\n",
       "      <td>4</td>\n",
       "      <td>experience</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>professional service together with prompt replies at every stage .</td>\n",
       "      <td>2</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>best of luck and thanks again .</td>\n",
       "      <td>2</td>\n",
       "      <td>luck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>could n't be happier and will definitely continue working together</td>\n",
       "      <td>9</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>quick response time .</td>\n",
       "      <td>1</td>\n",
       "      <td>response</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>very professional looking mascot and can adapt to unique ideas and requirements .</td>\n",
       "      <td>8</td>\n",
       "      <td>unique</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>a full custom build for a medium sized merchant is a huge job , with numerous tasks , inputs , opinions , and more .</td>\n",
       "      <td>16</td>\n",
       "      <td>tasks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>in this divided world we can only come together in our united pursuit of beauty in an artistic collaboration , and working with chris has been just that .</td>\n",
       "      <td>8</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>great designer , friendly , responsive , will order more work .</td>\n",
       "      <td>8</td>\n",
       "      <td>order</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>it 's been great working together again .</td>\n",
       "      <td>5</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>i was looking for someone to create a sample of a page from the children 's book i would like illustrated .</td>\n",
       "      <td>14</td>\n",
       "      <td>children</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>she also has a way of offering helpful suggestions while still considering the creative elements that i want to convey in my design .</td>\n",
       "      <td>13</td>\n",
       "      <td>creative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>thank you very much and i look forward to working together again .</td>\n",
       "      <td>10</td>\n",
       "      <td>together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>really good , imaginative designer and pretty much nailed it first time</td>\n",
       "      <td>6</td>\n",
       "      <td>pretty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>creative fulfillment .</td>\n",
       "      <td>0</td>\n",
       "      <td>creative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>as always , it 's a breeze to collaborate with him .</td>\n",
       "      <td>8</td>\n",
       "      <td>collaborate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>i shared the logo with co workers and they all loved it .</td>\n",
       "      <td>6</td>\n",
       "      <td>workers</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          review  \\\n",
       "3    working with ossobko visual was easy , all my vague requests and comments were immediately taken into account .                                              \n",
       "6    great professionalism by this company , excellent project management skills                                                                                   \n",
       "18   it 's a pleasure to collaborate with him !                                                                                                                    \n",
       "19   wilndr understood my description to communicate my brand in the logo design .                                                                                 \n",
       "27   fantastic designer , easy to work with , made changes to models without complaint .                                                                           \n",
       "30   excellent experience !                                                                                                                                        \n",
       "51   i have enjoyed working with chris and he has helped me to implement and strategize difficult and challenging situations .                                     \n",
       "67   nice results !                                                                                                                                                \n",
       "68   the first submission i received was the eventual winner , with only minor changes suggested by me .                                                           \n",
       "69   feel confident in choosing freshinnet ! !                                                                                                                     \n",
       "82   dayalmodal3322 ( d ) provided the winning submission to my contest .                                                                                          \n",
       "100  so grateful to have giorgia on my team .                                                                                                                      \n",
       "125  i feel very fortunate to have found id design team .                                                                                                          \n",
       "152  a pleasure to work with you james and we will be doing lots together going forward .                                                                          \n",
       "171  syakuro was the contest winner for our brand label and packing design challenge .                                                                             \n",
       "173  cheers                                                                                                                                                        \n",
       "185  he is able to bring characters to life and make them feel real .                                                                                              \n",
       "188  i am very happy with all that transpired between the design firm and the winning artist , alicia .                                                            \n",
       "189  very pleased with initial work and looking forward to working together again .                                                                                \n",
       "191  delivered the task on time .                                                                                                                                  \n",
       "219  great experience , thanks .                                                                                                                                   \n",
       "223  i have tried to resolve the issue with naren but have not been able to .                                                                                      \n",
       "225  the design concepts created by this artist were instant favorites among the great competition .                                                               \n",
       "234  perfect understanding of the project , quick to complete and very good quality report .                                                                       \n",
       "237  great communication but my job could not be completed due to technical situation                                                                              \n",
       "247  unreal attention to detail and response time .                                                                                                                \n",
       "260  the first logo has been a hit , and the second will be too .                                                                                                  \n",
       "262  excellent job in putting together what i envisioned .                                                                                                         \n",
       "265  this is my second order and will order again .                                                                                                                \n",
       "271  he took a vague concept and crafted a perfect logo for what we were looking for .                                                                             \n",
       "280  nick is amazingly knowledgeable in seo , and helped me better understand how my competitors were acquiring links and improving their search visibility .      \n",
       "281  i will definitely work with them again and look forward to continuing work and building a good working relationship .                                         \n",
       "298  even after lack of contact on my part , he was prompt in assisting me and making whatever changes i asked .                                                   \n",
       "310  will be working together in the future and am happy to have found them !                                                                                      \n",
       "311  so pleased with my experience !                                                                                                                               \n",
       "317  professional service together with prompt replies at every stage .                                                                                            \n",
       "318  best of luck and thanks again .                                                                                                                               \n",
       "321  could n't be happier and will definitely continue working together                                                                                            \n",
       "325  quick response time .                                                                                                                                         \n",
       "327  very professional looking mascot and can adapt to unique ideas and requirements .                                                                             \n",
       "330  a full custom build for a medium sized merchant is a huge job , with numerous tasks , inputs , opinions , and more .                                          \n",
       "336  in this divided world we can only come together in our united pursuit of beauty in an artistic collaboration , and working with chris has been just that .    \n",
       "344  great designer , friendly , responsive , will order more work .                                                                                               \n",
       "346  it 's been great working together again .                                                                                                                     \n",
       "348  i was looking for someone to create a sample of a page from the children 's book i would like illustrated .                                                   \n",
       "361  she also has a way of offering helpful suggestions while still considering the creative elements that i want to convey in my design .                         \n",
       "373  thank you very much and i look forward to working together again .                                                                                            \n",
       "378  really good , imaginative designer and pretty much nailed it first time                                                                                       \n",
       "387  creative fulfillment .                                                                                                                                        \n",
       "410  as always , it 's a breeze to collaborate with him .                                                                                                          \n",
       "449  i shared the logo with co workers and they all loved it .                                                                                                     \n",
       "\n",
       "     index     flagged_word  assignment  original  \n",
       "3    9      vague            0           0         \n",
       "6    1      professionalism  0           0         \n",
       "18   5      collaborate      0           0         \n",
       "19   5      communicate      0           0         \n",
       "27   11     models           0           0         \n",
       "30   1      experience       0           0         \n",
       "51   15     difficult        0           0         \n",
       "67   0      nice             0           0         \n",
       "68   8      winner           0           0         \n",
       "69   0      feel             0           0         \n",
       "82   6      winning          0           0         \n",
       "100  1      grateful         0           0         \n",
       "125  1      feel             0           0         \n",
       "152  13     together         0           0         \n",
       "171  4      winner           0           0         \n",
       "173  0      cheers           0           0         \n",
       "185  11     feel             0           0         \n",
       "188  11     firm             0           0         \n",
       "189  10     together         0           0         \n",
       "191  2      task             0           0         \n",
       "219  1      experience       0           0         \n",
       "223  13     able             0           0         \n",
       "225  13     competition      0           0         \n",
       "234  1      understanding    0           0         \n",
       "237  11     technical        0           0         \n",
       "247  5      response         0           0         \n",
       "260  13     too              0           0         \n",
       "262  4      together         0           0         \n",
       "265  4      order            0           0         \n",
       "271  3      vague            0           0         \n",
       "280  11     understand       0           0         \n",
       "281  18     relationship     0           0         \n",
       "298  13     assisting        0           0         \n",
       "310  3      together         0           0         \n",
       "311  4      experience       0           0         \n",
       "317  2      together         0           0         \n",
       "318  2      luck             0           0         \n",
       "321  9      together         0           0         \n",
       "325  1      response         0           0         \n",
       "327  8      unique           0           0         \n",
       "330  16     tasks            0           0         \n",
       "336  8      together         0           0         \n",
       "344  8      order            0           0         \n",
       "346  5      together         0           0         \n",
       "348  14     children         0           0         \n",
       "361  13     creative         0           0         \n",
       "373  10     together         0           0         \n",
       "378  6      pretty           0           0         \n",
       "387  0      creative         0           0         \n",
       "410  8      collaborate      0           0         \n",
       "449  6      workers          0           0         "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_cluster[FP_cluster.original == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
