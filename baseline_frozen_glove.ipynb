{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KAGGLE ONLY\n",
    "# from shutil import copyfile\n",
    "# copyfile(src=\"../input/inputs/generate_dataloaders.py\", dst=\"../working/generate_dataloaders.py\")\n",
    "# copyfile(src=\"../input/inputs/train_dataloader.p\", dst=\"../working/train_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/val_dataloader.p\", dst=\"../working/val_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/centroids_dataloader.p\", dst=\"../working/ground_truth_dataloader.p\")\n",
    "# copyfile(src=\"../input/inputs/dictionary.p\", dst=\"../working/dictionary.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zno22FtJPX9z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluation' from '/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/evaluation.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import get_mnist_dataset, get_data_loader\n",
    "#from utils import *\n",
    "#from models import *\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from generate_dataloaders import *\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import evaluation\n",
    "import importlib\n",
    "importlib.reload(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaJEVd0wPX94"
   },
   "source": [
    "## Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1029\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLzh007PX98"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = path + '/'\n",
    "data_dir = path +'/data/' #Uncomment for local system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Verify filenames are consistent*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq-jDGFIPX99"
   },
   "outputs": [],
   "source": [
    "train_loader = pkl.load(open(data_dir + 'train_dataloader.p','rb'))\n",
    "train_loader_labelled = pkl.load(open(data_dir + 'train_labeled_dataloader.p','rb'))\n",
    "train_loader_unlabelled = pkl.load(open(data_dir + 'train_unlabeled_dataloader.p','rb'))\n",
    "val_loader = pkl.load(open(data_dir + 'val_dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict = pkl.load(open(data_dir + 'dictionary.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda install pytorch torchvision -c pytorch\n",
    "## if torch.__version__ is not 1.3.1, run this cell then restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzz8lwNQPX-B",
    "outputId": "690cb77f-2525-4c5a-ea14-a162716e34d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE TRAINED WORD EMBEDDINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path):\n",
    "    with open(path) as f:\n",
    "        return dict(get_coefs(*line.strip().split(' ')) for line in tqdm(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(review_dict, embedding_index ,dim = 200):\n",
    "#     embedding_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((len(review_dict.tokens), dim))\n",
    "    unknown_words = []\n",
    "    \n",
    "    for word, i in review_dict.ids.items():\n",
    "        try:\n",
    "            embedding_matrix[i] = embedding_index[word]\n",
    "        except KeyError:\n",
    "            unknown_words.append(word)\n",
    "    return embedding_matrix, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove_twitter = '../input/glove-global-vectors-for-word-representation/glove.twitter.27B.200d.txt' #Change loc for local system\n",
    "glove_twitter = data_dir + 'glove.twitter.27B.200d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a57f2ea150489199dda4bc7788afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_index = load_embeddings(glove_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding_index,unknown_words = build_matrix(review_dict, embedding_index)\n",
    "del embedding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_dict.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4428"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# for word in unknown_words:\n",
    "#     print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt6N9QCPX-X"
   },
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puweJhdxPX-Y"
   },
   "source": [
    "NOTE: Data loader is defined as:\n",
    "- tuple: (tokens, flagged_index, problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8BZ-QhNPX-Z"
   },
   "outputs": [],
   "source": [
    "class neuralNetBow_glove(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n",
    "    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n",
    "    def __init__(self, opts):\n",
    "        super(neuralNetBow_glove, self).__init__()\n",
    "        self.embedding_matrix = opts['embedding_matrix']\n",
    "        self.vocab_size = self.embedding_matrix.shape[0]\n",
    "        self.embed_size = self.embedding_matrix.shape[1]\n",
    "        self.upweight = opts['upweight']\n",
    "        \n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embed_size, padding_idx=0)\n",
    "        self.embed.weight = nn.Parameter(torch.tensor(self.embedding_matrix,dtype=torch.float32))\n",
    "        self.embed.weight.requires_grad = False\n",
    "    \n",
    "    def forward(self, tokens, flagged_index):\n",
    "        batch_size, num_tokens = tokens.shape\n",
    "        embedding = self.embed(tokens)\n",
    "        \n",
    "        # upweight by flagged_index\n",
    "        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n",
    "        \n",
    "        # average across embeddings\n",
    "        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n",
    "        \n",
    "        return embedding_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGsqcnEtPX-a"
   },
   "source": [
    "### Clustering Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrgIYm8JPX-b"
   },
   "outputs": [],
   "source": [
    "class KMeansCriterion(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, embeddings, centroids):\n",
    "        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n",
    "        cluster_distances, cluster_assignments = distances.min(1)\n",
    "        loss = cluster_distances.sum()\n",
    "        return loss, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJohK2aPX-d"
   },
   "outputs": [],
   "source": [
    "def centroid_init(k, d, dataloader, model, current_device):\n",
    "    ## Here we ideally don't want to do randomized/zero initialization\n",
    "    centroid_sums = torch.zeros(k, d).to(current_device)\n",
    "    centroid_counts = torch.zeros(k).to(current_device)\n",
    "    for (tokens, labels, flagged_indices) in dataloader:\n",
    "        # cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n",
    "        cluster_assignments = labels.to(current_device)\n",
    "        \n",
    "        model.eval()\n",
    "        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n",
    "    \n",
    "        update_clusters(centroid_sums, centroid_counts,\n",
    "                        cluster_assignments, sentence_embed.to(current_device))\n",
    "    \n",
    "    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n",
    "    return centroid_means.clone()\n",
    "\n",
    "def update_clusters(centroid_sums, centroid_counts,\n",
    "                    cluster_assignments, embeddings):\n",
    "    k = centroid_sums.size(0)\n",
    "\n",
    "    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n",
    "    bin_counts = torch.bincount(cluster_assignments,minlength=k).type(torch.FloatTensor).to(current_device)\n",
    "    centroid_counts.add_(bin_counts)\n",
    "    \n",
    "    #np_cluster_assignments = cluster_assignments.to('cpu')\n",
    "    #np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n",
    "    #centroid_counts.add_(torch.FloatTensor(np_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3wynM7fPX-h"
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KglsYxPJPX-i"
   },
   "outputs": [],
   "source": [
    "def train_model(model, centroids, criterion, optimizer, train_loader, valid_loader, num_frozen_epochs=10, num_unfrozen_epochs=0, path_to_save=None, print_every = 1000):\n",
    "\n",
    "    train_losses=[]\n",
    "    val_losses=[]\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    if num_gpus > 0:\n",
    "        current_device = 'cuda'\n",
    "    else:\n",
    "        current_device = 'cpu'\n",
    "    \n",
    "    unfrozen = False\n",
    "    for epoch in range(num_frozen_epochs + num_unfrozen_epochs):\n",
    "        if epoch >= num_frozen_epochs:\n",
    "            print(\"*** UNFREEZING MODEL ***\")\n",
    "            model.embed.weight.requires_grad = True\n",
    "            unfrozen = True\n",
    "        print('{} | Epoch {}'.format(dt.datetime.now(), epoch))\n",
    "        model.train()\n",
    "        k, d = centroids.size()\n",
    "        centroid_sums = torch.zeros_like(centroids).to(current_device)\n",
    "        centroid_counts = torch.zeros(k).to(current_device)\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "        # run one epoch of gradient descent on autoencoders wrt centroids\n",
    "        for i, (tokens, labels, flagged_indices) in tqdm(enumerate(train_loader)):\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "\n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids.detach())\n",
    "\n",
    "            # run update step\n",
    "            optimizer.zero_grad()\n",
    "            if unfrozen:\n",
    "                cluster_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #Add loss to the epoch loss\n",
    "            total_epoch_loss += cluster_loss.data\n",
    "\n",
    "            # store centroid sums and counts in memory for later centering\n",
    "            update_clusters(centroid_sums, centroid_counts,\n",
    "                            cluster_assignments, sentence_embed)\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                losses = cluster_loss.data/len(tokens)\n",
    "                print('Average training loss at batch ',i,': %.3f' % losses)\n",
    "            \n",
    "        total_epoch_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(total_epoch_loss)\n",
    "        print('Average training loss after epoch ',epoch,': %.3f' % total_epoch_loss)\n",
    "        \n",
    "        # update centroids based on assignments from autoencoders\n",
    "        centroids = centroid_sums / (centroid_counts[:, None] + 1).to(current_device)\n",
    "        \n",
    "        # calculate validation loss after every epoch\n",
    "        total_validation_loss = 0\n",
    "        for i, (tokens, labels, flagged_indices) in enumerate(valid_loader):\n",
    "            model.eval()\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "            \n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n",
    "            \n",
    "            #Add loss to the validation loss\n",
    "            total_validation_loss += cluster_loss.data\n",
    "\n",
    "        total_validation_loss /= len(valid_loader.dataset)\n",
    "        val_losses.append(total_validation_loss)\n",
    "        print('Average validation loss after epoch ',epoch,': %.3f' % total_validation_loss)\n",
    "        \n",
    "        if path_to_save == None:\n",
    "            pass\n",
    "        else:\n",
    "            opts = {\"embedding_matrix\":model.embedding_matrix} #change options depending on model inputs required\n",
    "            torch.save(model.state_dict(), path_to_save+'model_dict.pt')\n",
    "            torch.save(centroids, path_to_save+'centroids')\n",
    "            torch.save(train_losses, path_to_save+'train_losses')\n",
    "            torch.save(val_losses, path_to_save+'val_losses')\n",
    "            torch.save(opts, path_to_save+'opts')\n",
    "            \n",
    "        \n",
    "    return model, centroids, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pBet75ZPX-m"
   },
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_save_directory(opts):\n",
    "    path = os.getcwd()\n",
    "    model_folder = 'baseline_randomized_embeddings/'\n",
    "    model_dir = path + '/models/' + model_folder\n",
    "    \n",
    "    # subfolder for each hyperparam config\n",
    "    num_unfrozen_epochs = opts['num_unfrozen_epochs']\n",
    "    upweight = opts['upweight']\n",
    "    subfolder = \"num_unfrozen_epochs=\"+str(num_unfrozen_epochs) + \",upweight=\"+str(upweight) + '/'\n",
    "    \n",
    "    # need to actually create these subfolders lol\n",
    "    try:\n",
    "        os.makedirs(model_dir + subfolder) # will throw error if subfolder already exists\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return model_dir + subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_config(opts):\n",
    "    model = neuralNetBow_glove(opts).to(current_device)\n",
    "    num_unfrozen_epochs = opts['num_unfrozen_epochs']\n",
    "    centroids = centroid_init(2, 200, train_loader_labelled, model, current_device)\n",
    "    criterion = KMeansCriterion().to(current_device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), 0.01, amsgrad=True)\n",
    "    path_to_save = get_save_directory(opts)\n",
    "    print(path_to_save)\n",
    "    \n",
    "    train_model(model, centroids, criterion, optimizer, train_loader, val_loader, num_frozen_epochs=10, num_unfrozen_epochs=num_unfrozen_epochs, path_to_save=path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=1/\n",
      "2019-12-07 21:32:33.565856 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6baf271c384808bacd2038be0fb12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.881\n",
      "Average training loss at batch  1000 : 1.239\n",
      "Average training loss at batch  2000 : 1.010\n",
      "Average training loss at batch  3000 : 1.009\n",
      "\n",
      "Average training loss after epoch  0 : 1.176\n",
      "Average validation loss after epoch  0 : 0.708\n",
      "2019-12-07 21:32:36.306309 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ad960d938d44f085b3bfa2c54289c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.474\n",
      "Average training loss at batch  1000 : 0.662\n",
      "Average training loss at batch  2000 : 0.659\n",
      "Average training loss at batch  3000 : 0.836\n",
      "\n",
      "Average training loss after epoch  1 : 0.659\n",
      "Average validation loss after epoch  1 : 0.704\n",
      "2019-12-07 21:32:39.299727 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5146a0f9aa3a4b0297f8f57ab77128d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.521\n",
      "Average training loss at batch  1000 : 0.543\n",
      "Average training loss at batch  2000 : 0.597\n",
      "Average training loss at batch  3000 : 0.610\n",
      "\n",
      "Average training loss after epoch  2 : 0.658\n",
      "Average validation loss after epoch  2 : 0.702\n",
      "2019-12-07 21:32:41.946083 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbd3de4a1f546feaa6965903c9c9dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.575\n",
      "Average training loss at batch  1000 : 0.502\n",
      "Average training loss at batch  2000 : 0.677\n",
      "Average training loss at batch  3000 : 0.677\n",
      "\n",
      "Average training loss after epoch  3 : 0.657\n",
      "Average validation loss after epoch  3 : 0.700\n",
      "2019-12-07 21:32:44.681060 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684cfcdfbcf147b2820605c27d9212b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.515\n",
      "Average training loss at batch  1000 : 0.735\n",
      "Average training loss at batch  2000 : 0.634\n",
      "Average training loss at batch  3000 : 0.567\n",
      "\n",
      "Average training loss after epoch  4 : 0.657\n",
      "Average validation loss after epoch  4 : 0.700\n",
      "2019-12-07 21:32:47.592024 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf7678276c3413b9dbe3ea8cc6e8a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.613\n",
      "Average training loss at batch  1000 : 0.607\n",
      "Average training loss at batch  2000 : 0.435\n",
      "Average training loss at batch  3000 : 0.574\n",
      "\n",
      "Average training loss after epoch  5 : 0.657\n",
      "Average validation loss after epoch  5 : 0.699\n",
      "2019-12-07 21:32:50.445854 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1216b70f6a479c9c9d3fcb75ad4a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.703\n",
      "Average training loss at batch  1000 : 0.584\n",
      "Average training loss at batch  2000 : 0.607\n",
      "Average training loss at batch  3000 : 0.807\n",
      "\n",
      "Average training loss after epoch  6 : 0.657\n",
      "Average validation loss after epoch  6 : 0.699\n",
      "2019-12-07 21:32:53.070265 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d335acea1b74ce995510f4a865ee7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.659\n",
      "Average training loss at batch  1000 : 0.413\n",
      "Average training loss at batch  2000 : 0.824\n",
      "Average training loss at batch  3000 : 0.802\n",
      "\n",
      "Average training loss after epoch  7 : 0.657\n",
      "Average validation loss after epoch  7 : 0.699\n",
      "2019-12-07 21:32:55.809207 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e86030f8f346c390dc98ee77c99dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.930\n",
      "Average training loss at batch  1000 : 0.582\n",
      "Average training loss at batch  2000 : 0.375\n",
      "Average training loss at batch  3000 : 0.756\n",
      "\n",
      "Average training loss after epoch  8 : 0.657\n",
      "Average validation loss after epoch  8 : 0.699\n",
      "2019-12-07 21:32:58.425980 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75434bf26c8446ffb93d7d71eb5369d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.486\n",
      "Average training loss at batch  1000 : 0.865\n",
      "Average training loss at batch  2000 : 0.705\n",
      "Average training loss at batch  3000 : 0.759\n",
      "\n",
      "Average training loss after epoch  9 : 0.657\n",
      "Average validation loss after epoch  9 : 0.699\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=5/\n",
      "2019-12-07 21:33:01.105937 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d169c43de02e451885c9d7e2d0260979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.011\n",
      "Average training loss at batch  1000 : 1.461\n",
      "Average training loss at batch  2000 : 1.289\n",
      "Average training loss at batch  3000 : 1.132\n",
      "\n",
      "Average training loss after epoch  0 : 1.310\n",
      "Average validation loss after epoch  0 : 0.983\n",
      "2019-12-07 21:33:03.698591 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e814b21ab14a0fa4087b65ddf82a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.893\n",
      "Average training loss at batch  1000 : 0.840\n",
      "Average training loss at batch  2000 : 0.949\n",
      "Average training loss at batch  3000 : 1.104\n",
      "\n",
      "Average training loss after epoch  1 : 0.914\n",
      "Average validation loss after epoch  1 : 0.981\n",
      "2019-12-07 21:33:06.280433 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9035ca375642fbbc5ea76308b611dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.889\n",
      "Average training loss at batch  1000 : 1.032\n",
      "Average training loss at batch  2000 : 0.723\n",
      "Average training loss at batch  3000 : 0.823\n",
      "\n",
      "Average training loss after epoch  2 : 0.913\n",
      "Average validation loss after epoch  2 : 0.980\n",
      "2019-12-07 21:33:08.885413 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b073c9d7e94c78ab26711bc6ee9e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.791\n",
      "Average training loss at batch  1000 : 0.847\n",
      "Average training loss at batch  2000 : 0.961\n",
      "Average training loss at batch  3000 : 0.687\n",
      "\n",
      "Average training loss after epoch  3 : 0.913\n",
      "Average validation loss after epoch  3 : 0.980\n",
      "2019-12-07 21:33:11.453566 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fcacc53cba4fee8d02c17497a9ef47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.139\n",
      "Average training loss at batch  1000 : 0.937\n",
      "Average training loss at batch  2000 : 0.988\n",
      "Average training loss at batch  3000 : 1.039\n",
      "\n",
      "Average training loss after epoch  4 : 0.913\n",
      "Average validation loss after epoch  4 : 0.980\n",
      "2019-12-07 21:33:14.016770 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd08cf2fd944f7b9ade0ac9893b6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.898\n",
      "Average training loss at batch  1000 : 0.839\n",
      "Average training loss at batch  2000 : 0.865\n",
      "Average training loss at batch  3000 : 1.073\n",
      "\n",
      "Average training loss after epoch  5 : 0.913\n",
      "Average validation loss after epoch  5 : 0.979\n",
      "2019-12-07 21:33:16.615597 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7db7d1c5c1940dfaf280a0d539acf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.794\n",
      "Average training loss at batch  1000 : 0.835\n",
      "Average training loss at batch  2000 : 0.722\n",
      "Average training loss at batch  3000 : 0.980\n",
      "\n",
      "Average training loss after epoch  6 : 0.913\n",
      "Average validation loss after epoch  6 : 0.979\n",
      "2019-12-07 21:33:19.185421 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84d9a67fbb3440183b510f8461283ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.840\n",
      "Average training loss at batch  1000 : 0.761\n",
      "Average training loss at batch  2000 : 0.861\n",
      "Average training loss at batch  3000 : 1.031\n",
      "\n",
      "Average training loss after epoch  7 : 0.913\n",
      "Average validation loss after epoch  7 : 0.979\n",
      "2019-12-07 21:33:21.782008 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068a8b3a8c1648d2b89bac49bb0c6ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.949\n",
      "Average training loss at batch  1000 : 0.811\n",
      "Average training loss at batch  2000 : 0.721\n",
      "Average training loss at batch  3000 : 1.220\n",
      "\n",
      "Average training loss after epoch  8 : 0.913\n",
      "Average validation loss after epoch  8 : 0.979\n",
      "2019-12-07 21:33:24.362047 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03d5c9992d04bb7b1149454b92bc6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.847\n",
      "Average training loss at batch  1000 : 1.030\n",
      "Average training loss at batch  2000 : 0.996\n",
      "Average training loss at batch  3000 : 0.703\n",
      "\n",
      "Average training loss after epoch  9 : 0.913\n",
      "Average validation loss after epoch  9 : 0.979\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=10/\n",
      "2019-12-07 21:33:27.158673 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874882ce4dc643abb08c97934d9b0e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.651\n",
      "Average training loss at batch  1000 : 1.951\n",
      "Average training loss at batch  2000 : 2.295\n",
      "Average training loss at batch  3000 : 1.691\n",
      "\n",
      "Average training loss after epoch  0 : 1.955\n",
      "Average validation loss after epoch  0 : 1.777\n",
      "2019-12-07 21:33:29.809373 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdffc33380844e70b015fb584011ce72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.446\n",
      "Average training loss at batch  1000 : 1.512\n",
      "Average training loss at batch  2000 : 1.558\n",
      "Average training loss at batch  3000 : 1.545\n",
      "\n",
      "Average training loss after epoch  1 : 1.642\n",
      "Average validation loss after epoch  1 : 1.768\n",
      "2019-12-07 21:33:32.394115 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5ac76009f148358bceb21c3dcbd09a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.579\n",
      "Average training loss at batch  1000 : 1.532\n",
      "Average training loss at batch  2000 : 1.329\n",
      "Average training loss at batch  3000 : 1.525\n",
      "\n",
      "Average training loss after epoch  2 : 1.634\n",
      "Average validation loss after epoch  2 : 1.768\n",
      "2019-12-07 21:33:34.970014 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8313c2c7b8994d2793cbcd4ab78b4794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.367\n",
      "Average training loss at batch  1000 : 1.766\n",
      "Average training loss at batch  2000 : 1.758\n",
      "Average training loss at batch  3000 : 1.612\n",
      "\n",
      "Average training loss after epoch  3 : 1.634\n",
      "Average validation loss after epoch  3 : 1.768\n",
      "2019-12-07 21:33:37.549314 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303d3b8280094ccf9e96110f2de5a8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.572\n",
      "Average training loss at batch  1000 : 1.876\n",
      "Average training loss at batch  2000 : 1.719\n",
      "Average training loss at batch  3000 : 2.004\n",
      "\n",
      "Average training loss after epoch  4 : 1.634\n",
      "Average validation loss after epoch  4 : 1.768\n",
      "2019-12-07 21:33:40.126518 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a167d9dd294059a0ab88d751cce233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.468\n",
      "Average training loss at batch  1000 : 1.546\n",
      "Average training loss at batch  2000 : 1.423\n",
      "Average training loss at batch  3000 : 1.578\n",
      "\n",
      "Average training loss after epoch  5 : 1.634\n",
      "Average validation loss after epoch  5 : 1.768\n",
      "2019-12-07 21:33:42.680785 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2200b9a0093047919f8a36c29aaf9ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.604\n",
      "Average training loss at batch  1000 : 2.194\n",
      "Average training loss at batch  2000 : 1.288\n",
      "Average training loss at batch  3000 : 1.664\n",
      "\n",
      "Average training loss after epoch  6 : 1.634\n",
      "Average validation loss after epoch  6 : 1.768\n",
      "2019-12-07 21:33:45.255074 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f72b7ffa5f4968aeadb7079f05eb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 2.026\n",
      "Average training loss at batch  1000 : 1.677\n",
      "Average training loss at batch  2000 : 1.797\n",
      "Average training loss at batch  3000 : 1.691\n",
      "\n",
      "Average training loss after epoch  7 : 1.634\n",
      "Average validation loss after epoch  7 : 1.768\n",
      "2019-12-07 21:33:47.810288 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3784582ad164fc69b849e38694d7f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.384\n",
      "Average training loss at batch  1000 : 1.598\n",
      "Average training loss at batch  2000 : 1.825\n",
      "Average training loss at batch  3000 : 1.750\n",
      "\n",
      "Average training loss after epoch  8 : 1.634\n",
      "Average validation loss after epoch  8 : 1.768\n",
      "2019-12-07 21:33:50.356092 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5488089dc14facb2a8f7dbc296d930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.639\n",
      "Average training loss at batch  1000 : 1.360\n",
      "Average training loss at batch  2000 : 1.470\n",
      "Average training loss at batch  3000 : 1.401\n",
      "\n",
      "Average training loss after epoch  9 : 1.634\n",
      "Average validation loss after epoch  9 : 1.768\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=25/\n",
      "2019-12-07 21:33:53.033448 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6741720c1384484495d899bbeb50f5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.023\n",
      "Average training loss at batch  1000 : 4.868\n",
      "Average training loss at batch  2000 : 5.224\n",
      "Average training loss at batch  3000 : 3.016\n",
      "\n",
      "Average training loss after epoch  0 : 4.487\n",
      "Average validation loss after epoch  0 : 4.778\n",
      "2019-12-07 21:33:55.572826 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806d8287bcf248e09dd2481e65527d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.392\n",
      "Average training loss at batch  1000 : 3.848\n",
      "Average training loss at batch  2000 : 4.887\n",
      "Average training loss at batch  3000 : 4.474\n",
      "\n",
      "Average training loss after epoch  1 : 4.373\n",
      "Average validation loss after epoch  1 : 4.772\n",
      "2019-12-07 21:33:58.140300 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c7b8dde1041789c707d6bace1a1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.832\n",
      "Average training loss at batch  1000 : 3.707\n",
      "Average training loss at batch  2000 : 4.554\n",
      "Average training loss at batch  3000 : 3.584\n",
      "\n",
      "Average training loss after epoch  2 : 4.363\n",
      "Average validation loss after epoch  2 : 4.764\n",
      "2019-12-07 21:34:00.764024 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620e393f25aa4e41b209d59239baa73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.044\n",
      "Average training loss at batch  1000 : 4.726\n",
      "Average training loss at batch  2000 : 4.112\n",
      "Average training loss at batch  3000 : 5.180\n",
      "\n",
      "Average training loss after epoch  3 : 4.350\n",
      "Average validation loss after epoch  3 : 4.730\n",
      "2019-12-07 21:34:03.339220 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3d8bcd28e44bc1937b3df0cd556e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.164\n",
      "Average training loss at batch  1000 : 4.118\n",
      "Average training loss at batch  2000 : 3.629\n",
      "Average training loss at batch  3000 : 3.880\n",
      "\n",
      "Average training loss after epoch  4 : 4.306\n",
      "Average validation loss after epoch  4 : 4.599\n",
      "2019-12-07 21:34:05.919196 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50dba1f74ad492ea1faa042cb408e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.485\n",
      "Average training loss at batch  1000 : 3.842\n",
      "Average training loss at batch  2000 : 4.507\n",
      "Average training loss at batch  3000 : 3.876\n",
      "\n",
      "Average training loss after epoch  5 : 4.156\n",
      "Average validation loss after epoch  5 : 4.487\n",
      "2019-12-07 21:34:08.527043 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76431f4a4e5944d9ac445b30a7f4b2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.893\n",
      "Average training loss at batch  1000 : 3.695\n",
      "Average training loss at batch  2000 : 3.607\n",
      "Average training loss at batch  3000 : 4.490\n",
      "\n",
      "Average training loss after epoch  6 : 4.028\n",
      "Average validation loss after epoch  6 : 4.479\n",
      "2019-12-07 21:34:11.087005 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d941388111466d9c1d218f5a729d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.004\n",
      "Average training loss at batch  1000 : 4.224\n",
      "Average training loss at batch  2000 : 4.567\n",
      "Average training loss at batch  3000 : 4.710\n",
      "\n",
      "Average training loss after epoch  7 : 4.019\n",
      "Average validation loss after epoch  7 : 4.478\n",
      "2019-12-07 21:34:13.691394 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e5ca40c8994d68a6facfff63c64457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.002\n",
      "Average training loss at batch  1000 : 4.111\n",
      "Average training loss at batch  2000 : 4.403\n",
      "Average training loss at batch  3000 : 5.325\n",
      "\n",
      "Average training loss after epoch  8 : 4.016\n",
      "Average validation loss after epoch  8 : 4.478\n",
      "2019-12-07 21:34:16.287595 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10878541765a4ba0841d1f0d6bd9e16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.287\n",
      "Average training loss at batch  1000 : 4.273\n",
      "Average training loss at batch  2000 : 3.575\n",
      "Average training loss at batch  3000 : 4.224\n",
      "\n",
      "Average training loss after epoch  9 : 4.015\n",
      "Average validation loss after epoch  9 : 4.479\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=1/\n",
      "2019-12-07 21:34:18.972415 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d9c00b6f294ed29adb69573016b031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.271\n",
      "Average training loss at batch  1000 : 0.964\n",
      "Average training loss at batch  2000 : 1.245\n",
      "Average training loss at batch  3000 : 0.998\n",
      "\n",
      "Average training loss after epoch  0 : 1.176\n",
      "Average validation loss after epoch  0 : 0.708\n",
      "2019-12-07 21:34:21.518990 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b153d60bce14f2186e77dc215890939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.641\n",
      "Average training loss at batch  1000 : 0.408\n",
      "Average training loss at batch  2000 : 0.457\n",
      "Average training loss at batch  3000 : 0.512\n",
      "\n",
      "Average training loss after epoch  1 : 0.659\n",
      "Average validation loss after epoch  1 : 0.704\n",
      "2019-12-07 21:34:24.127093 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bc91eed9f14e5794976f119393740e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.770\n",
      "Average training loss at batch  1000 : 0.604\n",
      "Average training loss at batch  2000 : 0.496\n",
      "Average training loss at batch  3000 : 0.816\n",
      "\n",
      "Average training loss after epoch  2 : 0.658\n",
      "Average validation loss after epoch  2 : 0.702\n",
      "2019-12-07 21:34:26.721423 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479d86684c144d0e94cd2c85feb11d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.603\n",
      "Average training loss at batch  1000 : 0.602\n",
      "Average training loss at batch  2000 : 0.680\n",
      "Average training loss at batch  3000 : 0.507\n",
      "\n",
      "Average training loss after epoch  3 : 0.657\n",
      "Average validation loss after epoch  3 : 0.700\n",
      "2019-12-07 21:34:29.288421 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293c0cc9a0844a61a7a963f98596bcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.711\n",
      "Average training loss at batch  1000 : 0.586\n",
      "Average training loss at batch  2000 : 0.709\n",
      "Average training loss at batch  3000 : 0.477\n",
      "\n",
      "Average training loss after epoch  4 : 0.657\n",
      "Average validation loss after epoch  4 : 0.700\n",
      "2019-12-07 21:34:31.836400 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1d2c4fa8154ca69ab374d1d57ca13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.631\n",
      "Average training loss at batch  1000 : 0.460\n",
      "Average training loss at batch  2000 : 0.575\n",
      "Average training loss at batch  3000 : 0.542\n",
      "\n",
      "Average training loss after epoch  5 : 0.657\n",
      "Average validation loss after epoch  5 : 0.699\n",
      "2019-12-07 21:34:34.432735 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b22266295214bd7b0372843257c87e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.581\n",
      "Average training loss at batch  1000 : 0.663\n",
      "Average training loss at batch  2000 : 0.539\n",
      "Average training loss at batch  3000 : 0.545\n",
      "\n",
      "Average training loss after epoch  6 : 0.657\n",
      "Average validation loss after epoch  6 : 0.699\n",
      "2019-12-07 21:34:37.019251 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20db80c781ec4868b950f979ff36f781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.782\n",
      "Average training loss at batch  1000 : 0.601\n",
      "Average training loss at batch  2000 : 0.526\n",
      "Average training loss at batch  3000 : 0.809\n",
      "\n",
      "Average training loss after epoch  7 : 0.657\n",
      "Average validation loss after epoch  7 : 0.699\n",
      "2019-12-07 21:34:39.577254 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec570df1789743aaa24007097e2da5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.622\n",
      "Average training loss at batch  1000 : 0.781\n",
      "Average training loss at batch  2000 : 0.606\n",
      "Average training loss at batch  3000 : 0.618\n",
      "\n",
      "Average training loss after epoch  8 : 0.657\n",
      "Average validation loss after epoch  8 : 0.699\n",
      "2019-12-07 21:34:42.135649 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a975f93f7a4e29a207064495cfc6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.525\n",
      "Average training loss at batch  1000 : 0.652\n",
      "Average training loss at batch  2000 : 0.702\n",
      "Average training loss at batch  3000 : 0.587\n",
      "\n",
      "Average training loss after epoch  9 : 0.657\n",
      "Average validation loss after epoch  9 : 0.699\n",
      "*** UNFREEZING MODEL ***\n",
      "2019-12-07 21:34:44.716827 | Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba6b7cced1744399db026df9ded0aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.756\n",
      "Average training loss at batch  1000 : 0.305\n",
      "Average training loss at batch  2000 : 0.199\n",
      "Average training loss at batch  3000 : 0.090\n",
      "\n",
      "Average training loss after epoch  10 : 0.225\n",
      "Average validation loss after epoch  10 : 0.114\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=5/\n",
      "2019-12-07 21:36:24.936429 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efa26cb5d9e4a5d9d6cb4065740d08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.019\n",
      "Average training loss at batch  1000 : 1.387\n",
      "Average training loss at batch  2000 : 1.058\n",
      "Average training loss at batch  3000 : 1.237\n",
      "\n",
      "Average training loss after epoch  0 : 1.310\n",
      "Average validation loss after epoch  0 : 0.983\n",
      "2019-12-07 21:36:27.514752 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc4010fe41349e88ed6ea9b5720b985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.039\n",
      "Average training loss at batch  1000 : 0.886\n",
      "Average training loss at batch  2000 : 1.036\n",
      "Average training loss at batch  3000 : 0.895\n",
      "\n",
      "Average training loss after epoch  1 : 0.914\n",
      "Average validation loss after epoch  1 : 0.981\n",
      "2019-12-07 21:36:30.107871 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd2fff7d57b43e38c12c72d4c2d25c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.890\n",
      "Average training loss at batch  1000 : 1.115\n",
      "Average training loss at batch  2000 : 1.059\n",
      "Average training loss at batch  3000 : 0.874\n",
      "\n",
      "Average training loss after epoch  2 : 0.913\n",
      "Average validation loss after epoch  2 : 0.980\n",
      "2019-12-07 21:36:32.675899 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c99553954404a2a95d4b6c6ab30fc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.840\n",
      "Average training loss at batch  1000 : 0.963\n",
      "Average training loss at batch  2000 : 0.871\n",
      "Average training loss at batch  3000 : 0.895\n",
      "\n",
      "Average training loss after epoch  3 : 0.913\n",
      "Average validation loss after epoch  3 : 0.980\n",
      "2019-12-07 21:36:35.635307 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4632f5bd3c9045ef864f576d5a022cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.977\n",
      "Average training loss at batch  1000 : 1.055\n",
      "Average training loss at batch  2000 : 0.928\n",
      "Average training loss at batch  3000 : 0.882\n",
      "\n",
      "Average training loss after epoch  4 : 0.913\n",
      "Average validation loss after epoch  4 : 0.980\n",
      "2019-12-07 21:36:38.654955 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0415b3e0c624c2eb443ab43d76dc2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.022\n",
      "Average training loss at batch  1000 : 1.030\n",
      "Average training loss at batch  2000 : 1.059\n",
      "Average training loss at batch  3000 : 0.966\n",
      "\n",
      "Average training loss after epoch  5 : 0.913\n",
      "Average validation loss after epoch  5 : 0.979\n",
      "2019-12-07 21:36:41.609378 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2727f6f72143c7bc7900a343543ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.947\n",
      "Average training loss at batch  1000 : 0.872\n",
      "Average training loss at batch  2000 : 1.010\n",
      "Average training loss at batch  3000 : 0.949\n",
      "\n",
      "Average training loss after epoch  6 : 0.913\n",
      "Average validation loss after epoch  6 : 0.979\n",
      "2019-12-07 21:36:44.817886 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447f12cc81254f889bb8df68fe780086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.057\n",
      "Average training loss at batch  1000 : 1.139\n",
      "Average training loss at batch  2000 : 0.918\n",
      "Average training loss at batch  3000 : 1.006\n",
      "\n",
      "Average training loss after epoch  7 : 0.913\n",
      "Average validation loss after epoch  7 : 0.979\n",
      "2019-12-07 21:36:47.625313 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be3e9e4a0b745609a0745a5a961d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.752\n",
      "Average training loss at batch  1000 : 0.848\n",
      "Average training loss at batch  2000 : 0.820\n",
      "Average training loss at batch  3000 : 1.050\n",
      "\n",
      "Average training loss after epoch  8 : 0.913\n",
      "Average validation loss after epoch  8 : 0.979\n",
      "2019-12-07 21:36:50.284772 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029dc6ecc3f746e3ad2a40d1c9bf888e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.053\n",
      "Average training loss at batch  1000 : 0.981\n",
      "Average training loss at batch  2000 : 0.850\n",
      "Average training loss at batch  3000 : 0.904\n",
      "\n",
      "Average training loss after epoch  9 : 0.913\n",
      "Average validation loss after epoch  9 : 0.979\n",
      "*** UNFREEZING MODEL ***\n",
      "2019-12-07 21:36:52.930719 | Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa1d6ac9beb49d8b1f8b6717b2b91d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.938\n",
      "Average training loss at batch  1000 : 0.182\n",
      "Average training loss at batch  2000 : 0.150\n",
      "Average training loss at batch  3000 : 0.066\n",
      "\n",
      "Average training loss after epoch  10 : 0.182\n",
      "Average validation loss after epoch  10 : 0.072\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=10/\n",
      "2019-12-07 21:38:40.766847 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c3329342f744ae9b1a7c68bb68b92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.737\n",
      "Average training loss at batch  1000 : 1.937\n",
      "Average training loss at batch  2000 : 1.663\n",
      "Average training loss at batch  3000 : 2.064\n",
      "\n",
      "Average training loss after epoch  0 : 1.955\n",
      "Average validation loss after epoch  0 : 1.777\n",
      "2019-12-07 21:38:43.367799 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd23407794a40f1a7d5923cbf0941c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.529\n",
      "Average training loss at batch  1000 : 1.250\n",
      "Average training loss at batch  2000 : 1.300\n",
      "Average training loss at batch  3000 : 1.485\n",
      "\n",
      "Average training loss after epoch  1 : 1.642\n",
      "Average validation loss after epoch  1 : 1.768\n",
      "2019-12-07 21:38:46.081467 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "543cbce936974c3991e2fd54708d0e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.746\n",
      "Average training loss at batch  1000 : 1.586\n",
      "Average training loss at batch  2000 : 1.565\n",
      "Average training loss at batch  3000 : 1.895\n",
      "\n",
      "Average training loss after epoch  2 : 1.634\n",
      "Average validation loss after epoch  2 : 1.768\n",
      "2019-12-07 21:38:48.902426 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54276235c674c0b96c18024cd47022d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.281\n",
      "Average training loss at batch  1000 : 1.603\n",
      "Average training loss at batch  2000 : 1.452\n",
      "Average training loss at batch  3000 : 1.817\n",
      "\n",
      "Average training loss after epoch  3 : 1.634\n",
      "Average validation loss after epoch  3 : 1.768\n",
      "2019-12-07 21:38:51.678151 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d507d2e138f7409698c96b4022d8471b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.502\n",
      "Average training loss at batch  1000 : 1.377\n",
      "Average training loss at batch  2000 : 1.836\n",
      "Average training loss at batch  3000 : 1.488\n",
      "\n",
      "Average training loss after epoch  4 : 1.634\n",
      "Average validation loss after epoch  4 : 1.768\n",
      "2019-12-07 21:38:54.379867 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5117803b19f4f0eaa7df2d868393e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.434\n",
      "Average training loss at batch  1000 : 1.856\n",
      "Average training loss at batch  2000 : 1.627\n",
      "Average training loss at batch  3000 : 1.420\n",
      "\n",
      "Average training loss after epoch  5 : 1.634\n",
      "Average validation loss after epoch  5 : 1.768\n",
      "2019-12-07 21:38:57.116850 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4dce9d629d45a7a833fb0983ab0f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.739\n",
      "Average training loss at batch  1000 : 1.555\n",
      "Average training loss at batch  2000 : 1.861\n",
      "Average training loss at batch  3000 : 1.578\n",
      "\n",
      "Average training loss after epoch  6 : 1.634\n",
      "Average validation loss after epoch  6 : 1.768\n",
      "2019-12-07 21:38:59.844192 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a70e0b18014fed9726c32ac29e0ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.631\n",
      "Average training loss at batch  1000 : 2.004\n",
      "Average training loss at batch  2000 : 1.710\n",
      "Average training loss at batch  3000 : 1.797\n",
      "\n",
      "Average training loss after epoch  7 : 1.634\n",
      "Average validation loss after epoch  7 : 1.768\n",
      "2019-12-07 21:39:02.555272 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9285f269c5cb40048167a48a248518cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.893\n",
      "Average training loss at batch  1000 : 1.709\n",
      "Average training loss at batch  2000 : 1.366\n",
      "Average training loss at batch  3000 : 1.345\n",
      "\n",
      "Average training loss after epoch  8 : 1.634\n",
      "Average validation loss after epoch  8 : 1.768\n",
      "2019-12-07 21:39:05.242678 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7842b9d238774c68b0347cd2020e5e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.746\n",
      "Average training loss at batch  1000 : 1.946\n",
      "Average training loss at batch  2000 : 1.571\n",
      "Average training loss at batch  3000 : 1.622\n",
      "\n",
      "Average training loss after epoch  9 : 1.634\n",
      "Average validation loss after epoch  9 : 1.768\n",
      "*** UNFREEZING MODEL ***\n",
      "2019-12-07 21:39:07.994291 | Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7441a550b2f0440f870acad2d5715490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 1.273\n",
      "Average training loss at batch  1000 : 0.142\n",
      "Average training loss at batch  2000 : 0.288\n",
      "Average training loss at batch  3000 : 0.056\n",
      "\n",
      "Average training loss after epoch  10 : 0.173\n",
      "Average validation loss after epoch  10 : 0.051\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=25/\n",
      "2019-12-07 21:40:56.079266 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f755b056b8554660977059d8c740bfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 5.026\n",
      "Average training loss at batch  1000 : 4.219\n",
      "Average training loss at batch  2000 : 4.989\n",
      "Average training loss at batch  3000 : 4.122\n",
      "\n",
      "Average training loss after epoch  0 : 4.487\n",
      "Average validation loss after epoch  0 : 4.778\n",
      "2019-12-07 21:40:58.861948 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252a34ce72864c68a47ca3a70b5560fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.775\n",
      "Average training loss at batch  1000 : 3.719\n",
      "Average training loss at batch  2000 : 4.554\n",
      "Average training loss at batch  3000 : 3.649\n",
      "\n",
      "Average training loss after epoch  1 : 4.373\n",
      "Average validation loss after epoch  1 : 4.772\n",
      "2019-12-07 21:41:01.804495 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213dcb0fb3a54f978ebc6693323d96d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.282\n",
      "Average training loss at batch  1000 : 4.945\n",
      "Average training loss at batch  2000 : 4.133\n",
      "Average training loss at batch  3000 : 4.666\n",
      "\n",
      "Average training loss after epoch  2 : 4.363\n",
      "Average validation loss after epoch  2 : 4.764\n",
      "2019-12-07 21:41:04.841928 | Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921d6cbfbfde40da95baaf189ba48ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.670\n",
      "Average training loss at batch  1000 : 3.090\n",
      "Average training loss at batch  2000 : 3.434\n",
      "Average training loss at batch  3000 : 3.420\n",
      "\n",
      "Average training loss after epoch  3 : 4.350\n",
      "Average validation loss after epoch  3 : 4.730\n",
      "2019-12-07 21:41:07.725588 | Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f869c55250147aa806705f7630c25eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.837\n",
      "Average training loss at batch  1000 : 4.882\n",
      "Average training loss at batch  2000 : 4.206\n",
      "Average training loss at batch  3000 : 4.185\n",
      "\n",
      "Average training loss after epoch  4 : 4.306\n",
      "Average validation loss after epoch  4 : 4.599\n",
      "2019-12-07 21:41:10.683803 | Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fe609c1d5b43a0b2a7e9bed580e0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.321\n",
      "Average training loss at batch  1000 : 3.713\n",
      "Average training loss at batch  2000 : 3.694\n",
      "Average training loss at batch  3000 : 3.570\n",
      "\n",
      "Average training loss after epoch  5 : 4.156\n",
      "Average validation loss after epoch  5 : 4.487\n",
      "2019-12-07 21:41:13.543877 | Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572108161cf44066800816c554c09883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 5.124\n",
      "Average training loss at batch  1000 : 3.199\n",
      "Average training loss at batch  2000 : 3.761\n",
      "Average training loss at batch  3000 : 4.481\n",
      "\n",
      "Average training loss after epoch  6 : 4.028\n",
      "Average validation loss after epoch  6 : 4.479\n",
      "2019-12-07 21:41:16.262903 | Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2b70c421764b339b3fb9f03a55a7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.912\n",
      "Average training loss at batch  1000 : 3.811\n",
      "Average training loss at batch  2000 : 4.464\n",
      "Average training loss at batch  3000 : 4.259\n",
      "\n",
      "Average training loss after epoch  7 : 4.019\n",
      "Average validation loss after epoch  7 : 4.478\n",
      "2019-12-07 21:41:19.105117 | Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b37efa646f24a5a828dfa548d58ce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 4.366\n",
      "Average training loss at batch  1000 : 4.018\n",
      "Average training loss at batch  2000 : 4.102\n",
      "Average training loss at batch  3000 : 4.452\n",
      "\n",
      "Average training loss after epoch  8 : 4.016\n",
      "Average validation loss after epoch  8 : 4.478\n",
      "2019-12-07 21:41:22.033415 | Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4456c6eecad24e94957ecd3f8fb6c9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.512\n",
      "Average training loss at batch  1000 : 4.104\n",
      "Average training loss at batch  2000 : 3.991\n",
      "Average training loss at batch  3000 : 3.010\n",
      "\n",
      "Average training loss after epoch  9 : 4.015\n",
      "Average validation loss after epoch  9 : 4.479\n",
      "*** UNFREEZING MODEL ***\n",
      "2019-12-07 21:41:25.054151 | Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ca30c5c0874ebf99ccd79a0d56c237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 3.592\n",
      "Average training loss at batch  1000 : 0.088\n",
      "Average training loss at batch  2000 : 0.062\n",
      "Average training loss at batch  3000 : 0.020\n",
      "\n",
      "Average training loss after epoch  10 : 0.216\n",
      "Average validation loss after epoch  10 : 0.041\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=2,upweight=1/\n",
      "2019-12-07 21:43:09.660214 | Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef73834d60841a4a7e097fc3a1ed7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.872\n",
      "Average training loss at batch  1000 : 1.087\n",
      "Average training loss at batch  2000 : 1.221\n",
      "Average training loss at batch  3000 : 1.561\n",
      "\n",
      "Average training loss after epoch  0 : 1.176\n",
      "Average validation loss after epoch  0 : 0.708\n",
      "2019-12-07 21:43:12.548812 | Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ee155e286a4eaeb317303e4737be2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.747\n",
      "Average training loss at batch  1000 : 0.495\n",
      "Average training loss at batch  2000 : 0.787\n",
      "Average training loss at batch  3000 : 0.636\n",
      "\n",
      "Average training loss after epoch  1 : 0.659\n",
      "Average validation loss after epoch  1 : 0.704\n",
      "2019-12-07 21:43:15.306159 | Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3937ad201754b7aba88cabffabb5970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss at batch  0 : 0.820\n",
      "Average training loss at batch  1000 : 0.750\n",
      "Average training loss at batch  2000 : 0.664\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-99247f402959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;34m'num_unfrozen_epochs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnum_unfrozen_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         }\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-e8ce453f639f>\u001b[0m in \u001b[0;36mtrain_config\u001b[0;34m(opts)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frozen_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_unfrozen_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_unfrozen_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_to_save\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-79a98b011edf>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, centroids, criterion, optimizer, train_loader, valid_loader, num_frozen_epochs, num_unfrozen_epochs, path_to_save, print_every)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# run one epoch of gradient descent on autoencoders wrt centroids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagged_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/DS-GA-1006/FairFrame/generate_dataloaders.py\u001b[0m in \u001b[0;36mpad_collate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mpad_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_list_of_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DS-GA-1006/FairFrame/generate_dataloaders.py\u001b[0m in \u001b[0;36mpad_list_of_tensors\u001b[0;34m(list_of_tensors, pad_token)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mpadded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mpadded_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "upweights = [1, 5, 10, 25]\n",
    "num_unfrozen_epochs_list = [0, 1]\n",
    "\n",
    "for num_unfrozen_epochs in num_unfrozen_epochs_list:\n",
    "    for upweight in upweights:\n",
    "        opts = {\n",
    "            'embedding_matrix': glove_embedding_index,\n",
    "            'num_unfrozen_epochs': num_unfrozen_epochs,\n",
    "            'upweight': upweight\n",
    "        }\n",
    "        train_config(opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this by itself, run:\n",
    "- Get Dataloaders\n",
    "- class definitions (model, clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_config(opts,verbose=True):\n",
    "    path_to_save = get_save_directory(opts)\n",
    "    print(path_to_save)\n",
    "    \n",
    "    model = neuralNetBow_glove(opts) #change according to model inputs\n",
    "    model.load_state_dict(torch.load(path_to_save+'model_dict.pt',map_location=lambda storage, loc: storage))\n",
    "    model = model.to(current_device)\n",
    "    criterion = KMeansCriterion().to(current_device)\n",
    "    centroids = torch.load(path_to_save+'centroids',map_location=lambda storage, loc: storage)\n",
    "    \n",
    "    TP_cluster, FP_cluster, results_dict = evaluation.main(model, centroids, val_loader, criterion, data_dir, current_device, verbose)\n",
    "    results_dict.update(opts)\n",
    "    return TP_cluster, FP_cluster, results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=1/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=5/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=10/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=0,upweight=25/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=1/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=5/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=10/\n",
      "/Users/elliotsilva/Desktop/DS-GA-1006/FairFrame/models/baseline_randomized_embeddings/num_unfrozen_epochs=1,upweight=25/\n"
     ]
    }
   ],
   "source": [
    "upweights = [1, 5, 10, 25]\n",
    "num_unfrozen_epochs_list = [2, 5, 10]\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "for num_unfrozen_epochs in num_unfrozen_epochs_list:\n",
    "    for upweight in upweights:\n",
    "        opts = {\n",
    "            'embedding_matrix': glove_embedding_index,\n",
    "            'num_unfrozen_epochs': num_unfrozen_epochs,\n",
    "            'upweight': upweight            \n",
    "        }\n",
    "        _, _, results_dict = evaluate_config(opts,False)\n",
    "        results_df = results_df.append(results_dict,ignore_index=True)\n",
    "        \n",
    "results_df = results_df[['num_unfrozen_epochs','upweight','Accuracy','F1 score','Precision','Recall',\n",
    "                        'TP_rate','FP_rate','FN_rate','TN_rate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_unfrozen_epochs</th>\n",
       "      <th>upweight</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>TP_rate</th>\n",
       "      <th>FP_rate</th>\n",
       "      <th>FN_rate</th>\n",
       "      <th>TN_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563356</td>\n",
       "      <td>0.677236</td>\n",
       "      <td>0.916185</td>\n",
       "      <td>0.537144</td>\n",
       "      <td>0.916185</td>\n",
       "      <td>0.083815</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.559714</td>\n",
       "      <td>0.674785</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.534968</td>\n",
       "      <td>0.913545</td>\n",
       "      <td>0.086455</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.205882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.557551</td>\n",
       "      <td>0.673527</td>\n",
       "      <td>0.912791</td>\n",
       "      <td>0.533646</td>\n",
       "      <td>0.912791</td>\n",
       "      <td>0.087209</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.202312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.563652</td>\n",
       "      <td>0.683933</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.536143</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.183099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.640279</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.505015</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.604410</td>\n",
       "      <td>0.688776</td>\n",
       "      <td>0.875486</td>\n",
       "      <td>0.567704</td>\n",
       "      <td>0.875486</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.563107</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.533679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>0.126214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.539094</td>\n",
       "      <td>0.665337</td>\n",
       "      <td>0.916318</td>\n",
       "      <td>0.522283</td>\n",
       "      <td>0.916318</td>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.838129</td>\n",
       "      <td>0.161871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_unfrozen_epochs  upweight  Accuracy  F1 score  Precision    Recall  \\\n",
       "0  0.0                  1.0       0.563356  0.677236  0.916185   0.537144   \n",
       "1  0.0                  5.0       0.559714  0.674785  0.913545   0.534968   \n",
       "2  0.0                  10.0      0.557551  0.673527  0.912791   0.533646   \n",
       "3  0.0                  25.0      0.563652  0.683933  0.944206   0.536143   \n",
       "4  1.0                  1.0       0.508683  0.640279  0.874510   0.505015   \n",
       "5  1.0                  5.0       0.604410  0.688776  0.875486   0.567704   \n",
       "6  1.0                  10.0      0.563107  0.695946  1.000000   0.533679   \n",
       "7  1.0                  25.0      0.539094  0.665337  0.916318   0.522283   \n",
       "\n",
       "    TP_rate   FP_rate   FN_rate   TN_rate  \n",
       "0  0.916185  0.083815  0.789474  0.210526  \n",
       "1  0.913545  0.086455  0.794118  0.205882  \n",
       "2  0.912791  0.087209  0.797688  0.202312  \n",
       "3  0.944206  0.055794  0.816901  0.183099  \n",
       "4  0.874510  0.125490  0.857143  0.142857  \n",
       "5  0.875486  0.124514  0.666667  0.333333  \n",
       "6  1.000000  0.000000  0.873786  0.126214  \n",
       "7  0.916318  0.083682  0.838129  0.161871  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
