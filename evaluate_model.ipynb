{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zno22FtJPX9z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from datasets import get_mnist_dataset, get_data_loader\n",
    "#from utils import *\n",
    "#from models import *\n",
    "\n",
    "import pickle as pkl\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from generate_dataloaders import *\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaJEVd0wPX94"
   },
   "source": [
    "## Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vi6hPzadPX95"
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_filename,val_filename):\n",
    "    path = os.getcwd()\n",
    "    data_dir = path + '/data/'\n",
    "    train_dataloader = pkl.load(open(data_dir + train_filename,'rb'))\n",
    "    val_dataloader = pkl.load(open(data_dir + val_filename,'rb'))\n",
    "    return train_dataloader,val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1029\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "random.seed(seed)  # Python random module.\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def _init_fn(worker_id):\n",
    "    np.random.seed(int(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nLzh007PX98"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "data_dir = path + '/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yq-jDGFIPX99"
   },
   "outputs": [],
   "source": [
    "train_loader,val_loader = get_dataloaders('train_dataloader.p','val_dataloader.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tQEhYjtPX-A"
   },
   "outputs": [],
   "source": [
    "centroids_dataloader = pkl.load(open(data_dir + 'centroids_dataloader.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%conda install pytorch torchvision -c pytorch\n",
    "## if torch.__version__ is not 1.3.1, run this cell then restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lzz8lwNQPX-B",
    "outputId": "690cb77f-2525-4c5a-ea14-a162716e34d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt6N9QCPX-X"
   },
   "source": [
    "## Neural Network Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puweJhdxPX-Y"
   },
   "source": [
    "NOTE: Data loader is defined as:\n",
    "- tuple: (tokens, flagged_index, problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W8BZ-QhNPX-Z"
   },
   "outputs": [],
   "source": [
    "class neuralNetBow(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    # NOTE: we can't use linear layer until we take weighted average, otherwise it will\n",
    "    # remember certain positions incorrectly (ie, 4th word has bigger weights vs 7th word)\n",
    "    def __init__(self, vocab_size, emb_dim, upweight=10):\n",
    "        super(neuralNetBow, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=2)\n",
    "        self.upweight = upweight\n",
    "    \n",
    "    def forward(self, tokens, flagged_index):\n",
    "        batch_size, num_tokens = tokens.shape\n",
    "        embedding = self.embed(tokens)\n",
    "#         print(embedding.shape) # below assumes \"batch_size x num_tokens x Emb_dim\" (VERIFY)\n",
    "        \n",
    "        # upweight by flagged_index\n",
    "#         print(type(embedding))\n",
    "        embedding[torch.LongTensor(range(batch_size)),flagged_index.type(torch.LongTensor),:] *= self.upweight\n",
    "        \n",
    "        # average across embeddings\n",
    "        embedding_ave = embedding.sum(1) / (num_tokens + self.upweight - 1)\n",
    "        \n",
    "        return embedding_ave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGsqcnEtPX-a"
   },
   "source": [
    "### Clustering Stuff (un-tailored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MrgIYm8JPX-b"
   },
   "outputs": [],
   "source": [
    "class KMeansCriterion(nn.Module):\n",
    "    \n",
    "    def __init__(self, lmbda):\n",
    "        super().__init__()\n",
    "        self.lmbda = lmbda\n",
    "    \n",
    "    def forward(self, embeddings, centroids):\n",
    "        distances = torch.sum((embeddings[:, None, :] - centroids)**2, 2)\n",
    "        cluster_distances, cluster_assignments = distances.min(1)\n",
    "        loss = self.lmbda * cluster_distances.sum()\n",
    "        return loss, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TJohK2aPX-d"
   },
   "outputs": [],
   "source": [
    "def centroid_init(k, d, dataloader, model, current_device):\n",
    "    ## Here we ideally don't want to do randomized/zero initialization\n",
    "    centroid_sums = torch.zeros(k, d).to(current_device)\n",
    "    centroid_counts = torch.zeros(k).to(current_device)\n",
    "    for (tokens, labels, flagged_indices) in dataloader:\n",
    "        # cluster_assignments = torch.LongTensor(tokens.size(0)).random_(k)\n",
    "        cluster_assignments = labels.to(current_device)\n",
    "        \n",
    "        model.eval()\n",
    "        sentence_embed = model(tokens.to(current_device),flagged_indices.to(current_device))\n",
    "    \n",
    "        update_clusters(centroid_sums, centroid_counts,\n",
    "                        cluster_assignments, sentence_embed.to(current_device))\n",
    "    \n",
    "    centroid_means = centroid_sums / centroid_counts[:, None].to(current_device)\n",
    "    return centroid_means.clone()\n",
    "\n",
    "def update_clusters(centroid_sums, centroid_counts,\n",
    "                    cluster_assignments, embeddings):\n",
    "    k = centroid_sums.size(0)\n",
    "\n",
    "    centroid_sums.index_add_(0, cluster_assignments, embeddings)\n",
    "    bin_counts = torch.bincount(cluster_assignments,minlength=k).type(torch.FloatTensor).to(current_device)\n",
    "    centroid_counts.add_(bin_counts)\n",
    "    \n",
    "    #np_cluster_assignments = cluster_assignments.to('cpu')\n",
    "    #np_counts = np.bincount(np_cluster_assignments.data.numpy(), minlength=k)\n",
    "    #centroid_counts.add_(torch.FloatTensor(np_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model_folder changes depending on which model we're evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell will change for each model\n",
    "model_folder = 'baseline_randomized_embeddings/'\n",
    "model_type = neuralNetBow\n",
    "criterion = KMeansCriterion(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_info(model_folder,model_type):\n",
    "    path = os.getcwd()\n",
    "    model_dir = path + '/models/' + model_folder\n",
    "\n",
    "    opts = torch.load(model_dir+'opts')\n",
    "    model = model_type(opts['vocab_size'], opts['emb_dim'])\n",
    "    model.load_state_dict(torch.load(model_dir+'model_dict.pt',map_location=lambda storage, loc: storage))\n",
    "    centroids = torch.load(model_dir+'centroids',map_location=lambda storage, loc: storage)\n",
    "    \n",
    "    return model, opts, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opts, centroids = load_model_info(model_folder,model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pBet75ZPX-m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "print(current_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mTFO2vp-PX-o"
   },
   "outputs": [],
   "source": [
    "model = model.to(current_device)\n",
    "criterion = criterion.to(current_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, centroids, val_loader, num_examples=None):\n",
    "    model.eval()\n",
    "    token_list = []\n",
    "    cluster_assignment_list = []\n",
    "    flagged_index_list = []\n",
    "    original_label = []\n",
    "    for i, (tokens, labels, flagged_indices) in enumerate(val_loader):\n",
    "            tokens = tokens.to(current_device)\n",
    "            labels = labels.to(current_device)\n",
    "            flagged_indices = flagged_indices.to(current_device)\n",
    "            \n",
    "            # forward pass and compute loss\n",
    "            sentence_embed = model(tokens,flagged_indices)\n",
    "            cluster_loss, cluster_assignments = criterion(sentence_embed, centroids)\n",
    "            \n",
    "            # store in list\n",
    "            token_list+=tokens.tolist()\n",
    "            flagged_index_list+=flagged_indices.tolist()\n",
    "            cluster_assignment_list+=cluster_assignments.tolist()\n",
    "            original_label+=labels.tolist()\n",
    "            \n",
    "    return token_list, flagged_index_list, cluster_assignment_list, original_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list, index_list, cluster_assignment_list, original_label = evaluate_model(model, centroids, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_assignment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pkl.load(open(data_dir+'dictionary.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(token_list,index_list,cluster_assignment_list,dictionary,original_label):\n",
    "    decoded_tokens = [' '.join(dictionary.decode_idx_seq(sent)) for sent in token_list]\n",
    "    reviews = [decoded for decoded in decoded_tokens]\n",
    "    flagged_words = [r.split()[i] for (r,i) in zip(reviews,index_list)]\n",
    "    reviews = [review.split('<pad>')[0] for review in reviews]\n",
    "    df_pred = pd.DataFrame({'review':reviews,'index':index_list,'flagged_word':flagged_words,\\\n",
    "                            'assignment':cluster_assignment_list,'original':original_label})\n",
    "    \n",
    "    pred_1 = df_pred[df_pred.assignment==1]\n",
    "    pred_0 = df_pred[df_pred.assignment==0]\n",
    "    \n",
    "    pred_1_manual_TP = len(pred_1[pred_1.original == 1]) / pred_1.shape[0]\n",
    "    pred_0_manual_TP = len(pred_0[pred_0.original == 1]) / pred_0.shape[0]\n",
    "    \n",
    "    if pred_1_manual_TP >= pred_0_manual_TP:\n",
    "        TP_cluster = pred_1\n",
    "        FP_cluster = pred_0\n",
    "    else:\n",
    "        TP_cluster = pred_0\n",
    "        FP_cluster = pred_1\n",
    "        TP_cluster.assignment =0\n",
    "        FP_cluster.assignment = 1\n",
    "\n",
    "    return TP_cluster, FP_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_cluster, FP_cluster = decode_predictions(token_list,index_list,cluster_assignment_list,dictionary,original_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_analysis(TP_cluster,FP_cluster):\n",
    "    TP_rate = len(TP_cluster[TP_cluster.original==1]) / TP_cluster.shape[0]\n",
    "    FP_rate = len(TP_cluster[TP_cluster.original==0]) / TP_cluster.shape[0]\n",
    "    FN_rate = len(TP_cluster[TP_cluster.original==1]) / TP_cluster.shape[0]\n",
    "    TN_rate = len(TP_cluster[TP_cluster.original==0]) / TP_cluster.shape[0]\n",
    "    \n",
    "    accuracy = (TP_rate + TN_rate) / (TP_rate + FP_rate + FN_rate + TN_rate)\n",
    "    precision = TP_rate / (TP_rate + FP_rate)\n",
    "    recall = TP_rate / (TP_rate + FN_rate)\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "    \n",
    "    print(\"TP_rate:\",TP_rate)\n",
    "    print(\"FP_rate:\",FP_rate)\n",
    "    print(\"FN_rate:\",FN_rate)\n",
    "    print(\"TN_rate:\",TN_rate)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Accuracy:\",accuracy)\n",
    "    print(\"Precision:\",precision)\n",
    "    print(\"Recall:\",recall)\n",
    "    print(\"F1 score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_rate: 0.8333333333333334\n",
      "FP_rate: 0.16666666666666666\n",
      "FN_rate: 0.8333333333333334\n",
      "TN_rate: 0.16666666666666666\n",
      "\n",
      "\n",
      "Accuracy: 0.5\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.5\n",
      "F1 score: 0.625\n"
     ]
    }
   ],
   "source": [
    "performance_analysis(TP_cluster,FP_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>index</th>\n",
       "      <th>flagged_word</th>\n",
       "      <th>assignment</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>experienced and talented designer who did an awesome work for the print materials for our brand .</td>\n",
       "      <td>0</td>\n",
       "      <td>experienced</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>david is obviously an expert on amazon selling techniques and had some fantastic insights .</td>\n",
       "      <td>4</td>\n",
       "      <td>expert</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>the final product was impressive , thoughtful and completed in a timely fashion .</td>\n",
       "      <td>4</td>\n",
       "      <td>impressive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>very creative designer.. loved how she accepted to edit frequently and was very patient.. definetly will work with holly again</td>\n",
       "      <td>1</td>\n",
       "      <td>creative</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>to start with this company tried hard to complete the tasks with enthusiasm but after i paid them the first payment they stopped communicating and completing the set tasks .</td>\n",
       "      <td>23</td>\n",
       "      <td>communicating</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>najla responded quickly to my initial enquiry and she was excited about my brief .</td>\n",
       "      <td>10</td>\n",
       "      <td>excited</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           review  \\\n",
       "10  experienced and talented designer who did an awesome work for the print materials for our brand .                                                                               \n",
       "16  david is obviously an expert on amazon selling techniques and had some fantastic insights .                                                                                     \n",
       "66  the final product was impressive , thoughtful and completed in a timely fashion .                                                                                               \n",
       "71  very creative designer.. loved how she accepted to edit frequently and was very patient.. definetly will work with holly again                                                  \n",
       "96  to start with this company tried hard to complete the tasks with enthusiasm but after i paid them the first payment they stopped communicating and completing the set tasks .   \n",
       "97  najla responded quickly to my initial enquiry and she was excited about my brief .                                                                                              \n",
       "\n",
       "    index   flagged_word  assignment  original  \n",
       "10  0      experienced    1           1         \n",
       "16  4      expert         1           1         \n",
       "66  4      impressive     1           0         \n",
       "71  1      creative       1           1         \n",
       "96  23     communicating  1           1         \n",
       "97  10     excited        1           1         "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>index</th>\n",
       "      <th>flagged_word</th>\n",
       "      <th>assignment</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard worker .</td>\n",
       "      <td>1</td>\n",
       "      <td>worker</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>even with the limitations of a template platform like wix ultrastjarna achieved a great result .</td>\n",
       "      <td>13</td>\n",
       "      <td>great</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>very helpful and reliable !</td>\n",
       "      <td>3</td>\n",
       "      <td>reliable</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we had a lot of wishes and demands but without hesitation he made the effort to give us the best experience possible .</td>\n",
       "      <td>20</td>\n",
       "      <td>experience</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fast work and very friendly !</td>\n",
       "      <td>4</td>\n",
       "      <td>friendly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>creative elements added to the logo that really captured the feeling we were looking for .</td>\n",
       "      <td>0</td>\n",
       "      <td>creative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>excellent job and awesome communication !</td>\n",
       "      <td>0</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>quick and great work .</td>\n",
       "      <td>2</td>\n",
       "      <td>great</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>rohitha provided me with the most amazing customer experience ever .</td>\n",
       "      <td>8</td>\n",
       "      <td>experience</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>mohd e has produced excellent high quality sound design for our animated youtube video [ login to view url ] .</td>\n",
       "      <td>4</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      review  \\\n",
       "0    hard worker .                                                                                                             \n",
       "1    even with the limitations of a template platform like wix ultrastjarna achieved a great result .                          \n",
       "2    very helpful and reliable !                                                                                               \n",
       "3    we had a lot of wishes and demands but without hesitation he made the effort to give us the best experience possible .    \n",
       "4    fast work and very friendly !                                                                                             \n",
       "..                              ...                                                                                            \n",
       "101  creative elements added to the logo that really captured the feeling we were looking for .                                \n",
       "102  excellent job and awesome communication !                                                                                 \n",
       "103  quick and great work .                                                                                                    \n",
       "104  rohitha provided me with the most amazing customer experience ever .                                                      \n",
       "105  mohd e has produced excellent high quality sound design for our animated youtube video [ login to view url ] .            \n",
       "\n",
       "     index flagged_word  assignment  original  \n",
       "0    1      worker       0           1         \n",
       "1    13     great        0           0         \n",
       "2    3      reliable     0           1         \n",
       "3    20     experience   0           0         \n",
       "4    4      friendly     0           1         \n",
       "..  ..           ...    ..          ..         \n",
       "101  0      creative     0           0         \n",
       "102  0      excellent    0           0         \n",
       "103  2      great        0           0         \n",
       "104  8      experience   0           0         \n",
       "105  4      excellent    0           0         \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
