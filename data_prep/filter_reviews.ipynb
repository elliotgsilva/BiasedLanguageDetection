{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Reviews\n",
    "This notebook processes the results from `all_reviews.p` by splitting reviews into sentences, filtering to keep only sentences containing lemmatizations of words in the flagged and replacements word lists. Each sentence is also tokenized. Final output in `master_df.p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "651WwPKkO9S8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import os\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk import tokenize\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ha87fkESQgmm"
   },
   "outputs": [],
   "source": [
    "# Points to data directory\n",
    "path = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHakcX2tO9TC"
   },
   "source": [
    "## Read in Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1490,
     "status": "ok",
     "timestamp": 1572980787297,
     "user": {
      "displayName": "Atul Gandhi",
      "photoUrl": "",
      "userId": "14583896042098624704"
     },
     "user_tz": 300
    },
    "id": "wirDi01SO9TD",
    "outputId": "782fd031-63b3-4b6e-83bf-7b3a13e3afbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111092\n"
     ]
    }
   ],
   "source": [
    "all_reviews = pkl.load(open(os.path.join(path, 'all_reviews.p'),'rb'))\n",
    "all_reviews = all_reviews[1:]\n",
    "print(len(all_reviews))\n",
    "#all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHD_CnvCO9TF"
   },
   "source": [
    "## Read in Replacement Words \n",
    "(Reviews that contain replacement words are no longer used in the current model implementation, but keeping this here for possible future use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3m19ct8wO9TG"
   },
   "outputs": [],
   "source": [
    "replacement_words_single_no_overlap = pd.read_csv(os.path.join(path, 'replacements_minus_flag.csv'),index_col=0)\n",
    "rwsno = list(replacement_words_single_no_overlap.rep_minus_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ek9DfkhO9TM"
   },
   "source": [
    "## Read in Flagged Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lww3EcR9O9TN"
   },
   "outputs": [],
   "source": [
    "flagged_words_single = pkl.load(open(os.path.join(path, 'flagged_words_single.p'),'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_dammdGO9TO"
   },
   "source": [
    "## Lemmatize Flagged and Replacement Word Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5MF9WO4O9TQ"
   },
   "outputs": [],
   "source": [
    "replacement_words_lemmatized = [wordnet_lemmatizer.lemmatize(w) for w in rwsno]\n",
    "flagged_words_lemmatized = [wordnet_lemmatizer.lemmatize(w) for w in flagged_words_single]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o28dj_LDO9TS"
   },
   "outputs": [],
   "source": [
    "replacement_words_set = set(replacement_words_lemmatized)\n",
    "flagged_words_set = set(flagged_words_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puEpCZm6O9TU"
   },
   "source": [
    "## Generate Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V2dsBEi8O9Tc"
   },
   "outputs": [],
   "source": [
    "flagged_words_set = [word.lower() for word in flagged_words_set]\n",
    "replacement_words_set = [word.lower() for word in replacement_words_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2738515,
     "status": "ok",
     "timestamp": 1572930537144,
     "user": {
      "displayName": "Atul Gandhi",
      "photoUrl": "",
      "userId": "14583896042098624704"
     },
     "user_tz": 300
    },
    "id": "tpVse6G9O9Te",
    "outputId": "c9a595bb-3b7a-43ff-a2d4-9692385c8cb3"
   },
   "outputs": [],
   "source": [
    "columns = ['review','flagged_word','flagged_index','problematic']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "\n",
    "flagged_count = 0\n",
    "replacement_count = 0\n",
    "\n",
    "for review in tqdm(all_reviews):\n",
    "    if type(review)==float:\n",
    "        continue\n",
    "    review_split = tokenize.sent_tokenize(review)\n",
    "    review_tokenized = [tokenize.word_tokenize(review_split[i]) for i in range(len(review_split))]\n",
    "    review_tokenized = [[w.lower() for w in review_sent] for review_sent in review_tokenized] \n",
    "    review_lemmatized = [[wordnet_lemmatizer.lemmatize(w) for w in review_sent] for review_sent in review_tokenized] \n",
    "    \n",
    "    for i in range(len(review_lemmatized)):\n",
    "        for j in range(len(review_lemmatized[i])): \n",
    "            if review_lemmatized[i][j] in flagged_words_set:\n",
    "                entry = {'review': review_tokenized[i],'flagged_word':review_tokenized[i][j],'flagged_index':j,'problematic':1}\n",
    "                df = df.append(entry,ignore_index=True)\n",
    "            elif review_lemmatized[i][j]  in replacement_words_set:\n",
    "                entry = {'review': review_tokenized[i],'flagged_word':review_tokenized[i][j],'flagged_index':j,'problematic':0}\n",
    "                df = df.append(entry,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SGEBC8pO9Ti"
   },
   "outputs": [],
   "source": [
    "# write python dict to a file\n",
    "output = open(os.path.join(path, 'master_df.p'), 'wb')\n",
    "pkl.dump(df, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCYV4gmxO9Tn"
   },
   "outputs": [],
   "source": [
    "len_reviews = [len(sentence) for sentence in df[\"review\"].to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Optimal Sentence Length Cut-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81fevhz_O9Tp",
    "outputId": "02689082-e0c1-4154-fb2a-c1afa7570e67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(len_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQXi4bvMO9Tr",
    "outputId": "3d5bd420-d343-41da-a81d-9ece37cb8280"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.14031e+05, 2.27360e+04, 2.11900e+03, 3.48000e+02, 7.00000e+01,\n",
       "        3.80000e+01, 1.00000e+01, 0.00000e+00, 7.00000e+00, 3.00000e+00]),\n",
       " array([  1. ,  18.3,  35.6,  52.9,  70.2,  87.5, 104.8, 122.1, 139.4,\n",
       "        156.7, 174. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(len_reviews, bins = 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "filter_reviews.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
